<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title>Byteman 4.0.3 has been released</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/zbnBLYWmMkQ/byteman-403-has-been-released.html" /><category term="feed_group_name_byteman" scheme="searchisko:content:tags" /><category term="feed_name_byteman" scheme="searchisko:content:tags" /><author><name>Andrew Dinn</name></author><id>searchisko:content:id:jbossorg_blog-byteman_4_0_3_has_been_released</id><updated>2018-07-03T08:02:00Z</updated><published>2018-07-03T08:02:00Z</published><content type="html">&lt;div class="post-body entry-content" id="post-body-3028514058787793602" itemprop="description articleBody"&gt;Byteman 4.0.3 is now available from the &lt;a class="moz-txt-link-freetext" href="http://www.jboss.org/byteman/downloads"&gt;Byteman downloads page&lt;/a&gt; and from the &lt;a class="moz-txt-link-freetext" href="https://oss.sonatype.org/index.html#nexus-search;quick%7Ebyteman"&gt;Maven Central repository&lt;/a&gt;. It is the latest release for use on JDK9+ runtimes. It is also recommended as the preferred release for use on JDK8- runtimes.&lt;/div&gt;&lt;div class="post-body entry-content" id="post-body-3028514058787793602" itemprop="description articleBody"&gt;&lt;br /&gt;&lt;/div&gt;&lt;div class="post-body entry-content" id="post-body-3028514058787793602" itemprop="description articleBody"&gt;Byteman 4.0.3 updates the 4.0.2 release with a small number of bug fixes and performance improvements. More details can be found in the &lt;a href="http://downloads.jboss.org/byteman/4.0.3/ReleaseNotes.txt"&gt;Release Notes&lt;/a&gt;.&lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/zbnBLYWmMkQ" height="1" width="1" alt=""/&gt;</content><summary>Byteman 4.0.3 is now available from the Byteman downloads page and from the Maven Central repository. It is the latest release for use on JDK9+ runtimes. It is also recommended as the preferred release for use on JDK8- runtimes. Byteman 4.0.3 updates the 4.0.2 release with a small number of bug fixes and performance improvements. More details can be found in the Release Notes.</summary><dc:creator>Andrew Dinn</dc:creator><dc:date>2018-07-03T08:02:00Z</dc:date><feedburner:origLink>http://bytemanblog.blogspot.com/2018/07/byteman-403-has-been-released.html</feedburner:origLink></entry><entry><title>A giant leap forward with multithreaded incremental solving</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/eOX1R_z6yKQ/AGiantLeapForwardWithMultithreadedIncrementalSolving.html" /><category term="algorithm" scheme="searchisko:content:tags" /><category term="benchmark" scheme="searchisko:content:tags" /><category term="feed_group_name_optaplanner" scheme="searchisko:content:tags" /><category term="feed_name_optaplanner" scheme="searchisko:content:tags" /><author><name>ge0ffrey</name></author><id>searchisko:content:id:jbossorg_blog-a_giant_leap_forward_with_multithreaded_incremental_solving</id><updated>2018-07-03T12:37:27Z</updated><published>2018-07-03T00:00:00Z</published><content type="html">&lt;div id="preamble"&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;OptaPlanner finally supports &lt;em&gt;multithreaded incremental solving&lt;/em&gt;. &lt;strong&gt;The speedup is spectacular. Even with just a few CPU cores, it triples the score calculation speed.&lt;/strong&gt; See the results below. To activate it, a single extra line in the configuration suffices.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;&lt;a href="https://issues.jboss.org/browse/PLANNER-76"&gt;The original feature request&lt;/a&gt; stems from 2007. Throughout the years, step by step, we diligently prepared the internal architecture for it. So now, after 10 years, we fully support it from &lt;code&gt;7.9.0.Final&lt;/code&gt; onwards.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;But why did it take so long to implement?&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_requirements"&gt;Requirements&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Let’s take a look at the requirements for multithreaded incremental solving:&lt;/p&gt; &lt;/div&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Horizontally scale an algorithm across CPU’s&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Don’t ruin the speedup of incremental score calculation&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Runs must be reproducible&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="_horizontally_scale_an_algorithm_across_cpu_s"&gt;Horizontally scale an algorithm across CPU’s&lt;/h3&gt; &lt;div class="paragraph"&gt; &lt;p&gt;There are several ways to use multiple threads without doing real multithreaded solving:&lt;/p&gt; &lt;/div&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Multitenancy&lt;/strong&gt;: Solve multiple datasets, one per thread.&lt;/p&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Works since the first OptaPlanner version.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Doesn’t do horizontal scaling on 1 dataset.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Multi bet solving&lt;/strong&gt;: Solve one dataset in multiple ways, completely independent of each other. Take the best result.&lt;/p&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Works since the first OptaPlanner version&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;It’s usually a waste of resources: use the Benchmarker during development instead to find the best algorithm in advance.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Doesn’t scale horizontally: the best result is marginally better than a single-threaded result and takes equally long.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Partitioned Search&lt;/strong&gt;: Split up one dataset and solve each one separately.&lt;/p&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Fully supported since OptaPlanner 7.0.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Scales horizontally at an expensive trade-off of solution quality, because &lt;a href="https://www.optaplanner.org/blog/2014/03/03/CanMapReduceSolvePlanningProblems.html"&gt;partitioning excludes optimal solutions&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;But none of these are real parallel heuristics, as shown in the bottom right corner below:&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="multiThreadingStrategies.png" alt="multiThreadingStrategies"&gt; &lt;/img&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;In real multithreaded solving, we solve 1 dataset, without partitioning, by offloading heavy calculations of 1 algorithm (which could be a composition of multiple algorithms) to multiple threads on separate CPU cores.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;In OptaPlanner’s Construction Heuristics and Local Search, the most CPU-expensive work is calculating the score of a move. For example in Tabu Search, each step (the outer iteration) evaluates around a 1000 moves. That’s measured as the &lt;em&gt;score calculation speed&lt;/em&gt;. It usually varies between 1k evaluated moves per second and 500k evaluated moves per second.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;&lt;em&gt;Multithreaded solving is just a matter of distributing the move evaluations of a step across multiple threads.&lt;/em&gt; That’s straightforward. There are even a few users that did this (most notably a space agency supplier), by hacking our code. But they didn’t see a performance gain. Quite the opposite actually (except with an easy score calculator). Those changes broke incremental score calculation. &lt;strong&gt;Multithreaded solving is easy. But multithreaded &lt;em&gt;incremental&lt;/em&gt; solving is hard.&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="_don_t_ruin_the_speedup_of_incremental_score_calculation"&gt;Don’t ruin the speedup of incremental score calculation&lt;/h3&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Ah, this brings us to incremental score calculation. The key to performance. It is the rocket science at the heart of OptaPlanner that brings massive scalability. And - for the few that have seen them - the cause of the notorious score corruption exception.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;What is incremental score calculation? For each move, we calculate the score of the solution state after applying that move. With non-incremental score calculation, the entire score is calculated from scratch. But with incremental score calculation, we only calculate the delta, as shown below. That’s far more efficient.&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="incrementalScoreCalculationEmployeeRostering.png" alt="incrementalScoreCalculationEmployeeRostering"&gt; &lt;/img&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;To put this in perspective: an incremental score calculator on a vehicle routing problem with 1000 locations, is theoretically around 500 times faster than a non-incremental score calculator. &lt;strong&gt;To offset the loss of an incremental solver on a dataset of a 1000 planning entities, a multithreaded non-incremental solver would need around 500 CPU cores (in theory).&lt;/strong&gt; In practice, the numbers vary, but the gain of incremental solving always outweights the gain of multithreaded solving.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Of course, now, we can have our cake and eat it too.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Each incremental score calculator is inherently single threaded, so each move thread has its own score calculator and its own solution state. Cloning either is too expensive. To evaluate a move on a move thread, with incremental score calculation, we must reuse the score calculator of the previous evaluation. This implies that the solution state must be in the exact same state to begin with. But because the outer step iterations change the solution state permanently, the move threads must sync up with the main solver thread after every step.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;It’s kinda like a multiplayer game of StarCraft.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;As soon as one thread goes out of sync, all calculations of that thread are corrupted, and the entire system is affected. But through a well designed orchestration of concurrent components (and multi-day test runs), we prevent race conditions. And it works. Like a charm.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Furthermore, the threads must be able to send moves to each other, even if it’s only to share the winning move. This too, posed a challenge. &lt;em&gt;OptaPlanner is an Object Orientated constraint solver&lt;/em&gt;, so it’s decision variables can be any valid Java type (not just booleans, numbers and floats), such as &lt;code&gt;Employee&lt;/code&gt; or &lt;code&gt;Foo&lt;/code&gt;. Those variables can sit in any domain class (called planning entities), such as &lt;code&gt;Shift&lt;/code&gt; or &lt;code&gt;Bar&lt;/code&gt;. The move instances reference those class instances. When a solution gets cloned to initiate a move thread, those planning entities, such as &lt;code&gt;Shift&lt;/code&gt; get cloned too. So when a move from thread A gets send to thread B, OptaPlanner rebases the move on the solution state of thread B. This replaces the references from the move instance to thread A’s solution state with the equivalent references of thread B’s solution state. Pretty nifty.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="_runs_must_be_reproducible"&gt;Runs must be reproducible&lt;/h3&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Reproducibility is king. The ability to run the same dataset through OptaPlanner twice and get the exact same result after the same number of steps (and at every step), is worth its weight in gold. To lose that, would make debugging, issue tracking and production audits extremely difficult.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;The inherent unpredictable nature of thread execution order on multi-core machines, makes reproducibility an interesting requirement. Combine that with the reliance of many optimization algorithms on a seeded random number generator (which is not thread-safe), for a real challenge.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;But we did it. We have 100% reproducibility. This involves several ingenious mechanisms, such as using a master seeded random to generate a seeded random per thread, generating a predictable number of selected, buffered moves (because move generation often relies on the random generator too) and reordering evaluated moves in their originally selected order when they come back from the move threads.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_the_configuration"&gt;The configuration&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Multithreaded incremental solving is easy to activate. Just add a &lt;code&gt;&amp;lt;moveThreadCount&amp;gt;&lt;/code&gt; line in your solver config:&lt;/p&gt; &lt;/div&gt; &lt;div class="listingblock"&gt; &lt;div class="content"&gt; &lt;pre class="highlight nowrap"&gt;&lt;code class="language-java" data-lang="java"&gt;&amp;lt;solver&amp;gt; &amp;lt;moveThreadCount&amp;gt;4&amp;lt;/moveThreadCount&amp;gt; ... &amp;lt;/solver&amp;gt;&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;This basically donates 4 extra CPU cores to the solver. Use &lt;code&gt;AUTO&lt;/code&gt; to have OptaPlanner deduce it automatically. Optionally, specify a &lt;code&gt;&amp;lt;threadFactoryClass&amp;gt;&lt;/code&gt; for environments that don’t like arbitrary thread creation.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;It combines with every other feature, including other multithreading strategies (such as multitenancy, Partitioned Search, …​), if you have enough CPU cores to pull it off.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_the_benchmarks"&gt;The benchmarks&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="sect2"&gt; &lt;h3 id="_methodology"&gt;Methodology&lt;/h3&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Using optaplanner-benchmark, I ran a set of macro benchmarks:&lt;/p&gt; &lt;/div&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;On a 64-bit &lt;strong&gt;8-core&lt;/strong&gt; Intel i7-4790 desktop with 32GB physical RAM&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Using OpenJDK 1.8.0_171 on Linux&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;With the JVM max heap (&lt;code&gt;-Xmx&lt;/code&gt;) set to 4GB.&lt;/p&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;I also tried 2GB and those results were worse, especially for a higher of move threads.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;So when increasing the number of move threads, it’s important to increase the max memory too.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;With logging set to &lt;code&gt;info&lt;/code&gt; logging.&lt;/p&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;I also tried &lt;code&gt;debug&lt;/code&gt; logging and those results were clearly worse (because the faster it runs, the more debug logging it does).&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;It’s recommended to &lt;a href="https://www.optaplanner.org/blog/2015/02/23/HowFastIsLogging.html"&gt;avoid debug logging in production&lt;/a&gt; anyway.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;With score DRL.&lt;/p&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;I also tried with the incremental java calculator and those results had more moves/second, but a lower relative gain per move thread (due to higher congestion).&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;5 minutes per dataset&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="_results_on_the_vehicle_routing_problem_vrp"&gt;Results on the vehicle routing problem (VRP)&lt;/h3&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Below are the results on different VRP datasets for a First Fit Decreasing (the Construction Heuristic) followed by Tabu Search (the Local Search). Higher is better.&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="multithreadedSolvingVrpTabuSearch.png" alt="multithreadedSolvingVrpTabuSearch"&gt; &lt;/img&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;The blue bar is the traditional, single-threaded OptaPlanner. It has an average score calculation speed of &lt;code&gt;26,947&lt;/code&gt; moves per second. That goes up to &lt;code&gt;45,565&lt;/code&gt; with 2 move threads, to &lt;code&gt;80,757&lt;/code&gt; with 4 move threads and to &lt;code&gt;88,410&lt;/code&gt; with 6 move threads.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;&lt;strong&gt;So by donating more CPU cores to OptaPlanner, it uses a fraction of the time to reach the same result.&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;On other Local Search algorithms, such as Late Acceptance, we see similar results:&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="multithreadedSolvingVrpLateAcceptance.png" alt="multithreadedSolvingVrpLateAcceptance"&gt; &lt;/img&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Late Acceptance is a fast stepping algorithm (especially in the beginning), which implies that it has less moves per step. Yet, it has a similar relative speed gain for the Vehicle Routing Problem.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;We also see a slight reduction of the relative speed gain on the biggest dataset with 2750 VRP locations, but I suspect this might be because the 4GB max heap memory is too low for it to function at full efficiency. I’ll investigate this further.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="_results_on_nurse_rostering"&gt;Results on nurse rostering&lt;/h3&gt; &lt;div class="paragraph"&gt; &lt;p&gt;I also ran benchmarks on the nurse rostering use case, but with a JVM max heap (&lt;code&gt;-Xmx&lt;/code&gt;) set to 2GB. Here I tried Tabu Search, Simulated Annealing and Late Acceptance:&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="multithreadedSolvingNurseRosteringTabuSearch.png" alt="multithreadedSolvingNurseRosteringTabuSearch"&gt; &lt;/img&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="multithreadedSolvingNurseRosteringSimulatedAnnealing.png" alt="multithreadedSolvingNurseRosteringSimulatedAnnealing"&gt; &lt;/img&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="multithreadedSolvingNurseRosteringLateAcceptance.png" alt="multithreadedSolvingNurseRosteringLateAcceptance"&gt; &lt;/img&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;In all 3 case, we see a welcome speed gain, but Tabu Search (a slow stepping algorithms) has a bigger relative gain than the others (which are fast stepping algorithms).&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;In any case, it’s clear that &lt;em&gt;your mileage may vary&lt;/em&gt;, depending on the use case and other factors.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_future_improvements"&gt;Future improvements&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;As we increase the number of move threads or decrease the time to evaluate a single move on one thread, we see a higher congestion on the inter-thread communication queues, leading to a lower relative scalability gain. There are several ways to deal with that and we’ll be investigating such internal improvements in the future.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_conclusion"&gt;Conclusion&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;&lt;em&gt;All your CPU are belong to OptaPlanner.&lt;/em&gt;&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;With a single extra configuration line, &lt;a href="https://www.optaplanner.org/"&gt;OptaPlanner&lt;/a&gt; can reach the same high-quality solution in a fraction of the time. If you have CPU cores to spare, of course.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/eOX1R_z6yKQ" height="1" width="1" alt=""/&gt;</content><summary>OptaPlanner finally supports multithreaded incremental solving. The speedup is spectacular. Even with just a few CPU cores, it triples the score calculation speed. See the results below. To activate it, a single extra line in the configuration suffices. The original feature request stems from 2007. Throughout the years, step by step, we diligently prepared the internal architecture for it. So now,...</summary><dc:creator>ge0ffrey</dc:creator><dc:date>2018-07-03T00:00:00Z</dc:date><feedburner:origLink>https://www.optaplanner.org/blog/2018/07/03/AGiantLeapForwardWithMultithreadedIncrementalSolving.html</feedburner:origLink></entry><entry><title>June 2018 ISO C++ Meeting Trip Report (Core Language)</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/ZE9JEpKfMjs/" /><category term="C standardization" scheme="searchisko:content:tags" /><category term="C++" scheme="searchisko:content:tags" /><category term="community" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="gcc" scheme="searchisko:content:tags" /><category term="GCC compiler collection" scheme="searchisko:content:tags" /><category term="GNU Compiler Collection" scheme="searchisko:content:tags" /><category term="iso" scheme="searchisko:content:tags" /><category term="Programming Languages" scheme="searchisko:content:tags" /><category term="Red Hat Developer Toolset" scheme="searchisko:content:tags" /><category term="standards" scheme="searchisko:content:tags" /><author><name>Jason Merrill</name></author><id>searchisko:content:id:jbossorg_blog-june_2018_iso_c_meeting_trip_report_core_language</id><updated>2018-07-02T20:46:21Z</updated><published>2018-07-02T20:46:21Z</published><content type="html">&lt;p&gt;The Summer 2018 ISO C++ standards committee meeting this year was back in Rapperswil, Switzerland. The new features for C++2a are coming fast now; the Core language working group had very little time for issue processing because of all the proposal papers coming to us from the Evolution working group.&lt;/p&gt; &lt;p&gt;Red Hat sent three of us to the meeting, to cover different tracks: myself (Core), Jonathan Wakely (Library), and Torvald Riegel (Parallelism/Concurrency).  Overall, I thought the meeting was very successful; we made significant progress in a lot of areas.&lt;/p&gt; &lt;p&gt;New C++ language features that were accepted at this meeting:&lt;span id="more-504517"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;Accepted features&lt;/h2&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="http://wg21.link/p0542"&gt;Contracts&lt;/a&gt;—&lt;/strong&gt;This feature provides a structured way to express function preconditions and postconditions in code, e.g.&lt;/p&gt; &lt;pre&gt;int f(int x)   [[expects: x&amp;#62;0]]   [[ensures r: r&amp;#62;0]];&lt;/pre&gt; &lt;p&gt;&lt;a href="http://wg21.link/p0732"&gt;&lt;strong&gt;Literal class types for non-type template parameters&lt;/strong&gt;&lt;/a&gt;—These will roughly have the semantics of a reference to a constexpr variable.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="http://wg21.link/p0722"&gt;Destroying operator delete&lt;/a&gt;&lt;/strong&gt;—One use of this feature is for cases when a class is allocated together in a block with other data, such as a trailing buffer.  Where in C++17 deleting a pointer to such a class would call sized &lt;tt&gt;::operator delete&lt;/tt&gt; with the wrong size, with this proposal the user can adjust the size appropriately.&lt;/p&gt; &lt;p&gt;&lt;a href="http://wg21.link/p1064"&gt;&lt;strong&gt;Allowing virtual function calls in constant expression evaluation&lt;/strong&gt;&lt;/a&gt;—This one is somewhat self explanatory.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="http://wg21.link/p0892"&gt;explicit(bool)&lt;/a&gt;&lt;/strong&gt;—Various wrapper types in the C++ standard library currently need to use SFINAE with two separate constructors in order to make construction explicit based on whether construction of the wrapped type(s) is explicit.  With this feature library writers can write a single conditionally-explicit constructor instead.&lt;/p&gt; &lt;p&gt;One semantic change that I wanted to call attention to:&lt;/p&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="http://wg21.link/p1008"&gt;Prohibit aggregates with user-declared constructors&lt;/a&gt;&lt;/strong&gt;—Currently, some code uses patterns like:&lt;/p&gt; &lt;pre&gt;struct A {   A() = delete; // prohibit default-initialization   B b; }; A a = { B(); }; // OK, aggregate initialization&lt;/pre&gt; &lt;p&gt;to encourage users of the A type to use aggregate initialization.  But this also allows:&lt;/p&gt; &lt;pre&gt;A a = { }; // also aggregate initialization&lt;/pre&gt; &lt;p&gt;and the deleted default constructor might also have been intended to prevent this, since it&amp;#8217;s also initializing from no elements.  So this proposal changes A, or any class with a user-declared constructor, to be non-aggregate; if the A author wants aggregate initialization, they must remove the default constructor declaration.  I argued that there should be an exception for copy and move constructors, but lost.  But it is still possible to prevent default initialization of an aggregate by using a trailing empty member with the recently added &lt;tt&gt;[[no_unique_address]]&lt;/tt&gt; attribute:&lt;/p&gt; &lt;pre&gt;struct B { B(); }; struct deleted_default { deleted_default() = delete; }; struct A {   B b;   [[no_unique_address]] deleted_default _d; // prevent default-initialization }; A a;           // error, deleted implicitly-declared default constructor A a2 { };      // ok, aggregate initialization A a3 { B() };  // ok, aggregate initialization&lt;/pre&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;h2&gt;Papers that weren&amp;#8217;t accepted&lt;/h2&gt; &lt;p&gt;There were several more papers that we worked on, but weren&amp;#8217;t ready by the end of the week, including:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="http://wg21.link/p0482"&gt;char8_t type for UTF-8 characters&lt;/a&gt;, to go along with the existing char16_t and char32_t types. char8_t will not have the problematic aliasing properties of plain char.&lt;/li&gt; &lt;li&gt;&lt;a href="http://wg21.link/p0960"&gt;parenthesized initialization of aggregate classes&lt;/a&gt;, to be treated in overload resolution like a built-in constructor taking the types of the aggregate elements.&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Concepts, Modules, and Coroutines&lt;/h2&gt; &lt;p&gt;The big three feature TSes (technical specifications) are still working toward consensus.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Concepts&lt;/strong&gt; (partially merged last year)—There was a lot of discussion about terse function declaration syntax, exploring alternatives to the syntax in the TS, and I think things are looking hopeful for a successful compromise at the next meeting.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Modules—&lt;/strong&gt;Modules also seem to be on track for successful compromise; there was consensus for merging some of the ATOM proposal into the TS working paper, and we&amp;#8217;ll see the result at the next meeting.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Coroutines—&lt;/strong&gt;Merging the coroutines TS was up for a vote at the end of the meeting, but failed.  There was an alternative proposal considered at the meeting, but the next step isn&amp;#8217;t as clear to me here as it is with Concepts and Modules.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;We also voted to send out the (static) Reflection TS for public comment at this meeting.  This proposal uses meta-types as the handle through which the user can ask questions about the program, in much the same way that type traits use class templates.&lt;/p&gt; &lt;p&gt;One broadly interesting bit from discussion of core issues at the end of the week:&lt;/p&gt; &lt;p&gt;&lt;a href="http://wg21.link/cwg2335"&gt;&lt;strong&gt;2335&lt;/strong&gt;&lt;/a&gt;—There seems to be a growing consensus in the core working group (CWG) that we should be more flexible about dependencies between delayed-parse regions, allowing on-demand parsing in much the way we do on-demand instantiation of such regions in a class template.  This has previously been deemed impractical, but there is less concern about that now.&lt;/p&gt; &lt;p&gt;The next meeting will be in San Diego in November.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F07%2F02%2Fiso-cpp-summer-2018-core-language%2F&amp;#38;linkname=June%202018%20ISO%20C%2B%2B%20Meeting%20Trip%20Report%20%28Core%20Language%29" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F07%2F02%2Fiso-cpp-summer-2018-core-language%2F&amp;#38;linkname=June%202018%20ISO%20C%2B%2B%20Meeting%20Trip%20Report%20%28Core%20Language%29" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F07%2F02%2Fiso-cpp-summer-2018-core-language%2F&amp;#38;linkname=June%202018%20ISO%20C%2B%2B%20Meeting%20Trip%20Report%20%28Core%20Language%29" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F07%2F02%2Fiso-cpp-summer-2018-core-language%2F&amp;#38;linkname=June%202018%20ISO%20C%2B%2B%20Meeting%20Trip%20Report%20%28Core%20Language%29" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F07%2F02%2Fiso-cpp-summer-2018-core-language%2F&amp;#38;linkname=June%202018%20ISO%20C%2B%2B%20Meeting%20Trip%20Report%20%28Core%20Language%29" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F07%2F02%2Fiso-cpp-summer-2018-core-language%2F&amp;#38;linkname=June%202018%20ISO%20C%2B%2B%20Meeting%20Trip%20Report%20%28Core%20Language%29" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F07%2F02%2Fiso-cpp-summer-2018-core-language%2F&amp;#38;linkname=June%202018%20ISO%20C%2B%2B%20Meeting%20Trip%20Report%20%28Core%20Language%29" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F07%2F02%2Fiso-cpp-summer-2018-core-language%2F&amp;#38;linkname=June%202018%20ISO%20C%2B%2B%20Meeting%20Trip%20Report%20%28Core%20Language%29" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F07%2F02%2Fiso-cpp-summer-2018-core-language%2F&amp;#38;title=June%202018%20ISO%20C%2B%2B%20Meeting%20Trip%20Report%20%28Core%20Language%29" data-a2a-url="https://developers.redhat.com/blog/2018/07/02/iso-cpp-summer-2018-core-language/" data-a2a-title="June 2018 ISO C++ Meeting Trip Report (Core Language)"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/07/02/iso-cpp-summer-2018-core-language/"&gt;June 2018 ISO C++ Meeting Trip Report (Core Language)&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/ZE9JEpKfMjs" height="1" width="1" alt=""/&gt;</content><summary>The Summer 2018 ISO C++ standards committee meeting this year was back in Rapperswil, Switzerland. The new features for C++2a are coming fast now; the Core language working group had very little time for issue processing because of all the proposal papers coming to us from the Evolution working group. Red Hat sent three of us to the meeting, to cover different tracks: myself (Core), Jonathan Wakel...</summary><dc:creator>Jason Merrill</dc:creator><dc:date>2018-07-02T20:46:21Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2018/07/02/iso-cpp-summer-2018-core-language/</feedburner:origLink></entry><entry><title>RESTEasy 3.6.0.Final and 4.0.0.Beta4</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/Hbol_JezbYc/resteasy-360final-and-400beta4" /><category term="feed_group_name_resteasy" scheme="searchisko:content:tags" /><category term="feed_name_resteasy" scheme="searchisko:content:tags" /><category term="JAX-RS" scheme="searchisko:content:tags" /><category term="jaxrs" scheme="searchisko:content:tags" /><category term="reactive" scheme="searchisko:content:tags" /><category term="resteasy" scheme="searchisko:content:tags" /><category term="rxjava" scheme="searchisko:content:tags" /><author><name>Alessio Soldano</name></author><id>searchisko:content:id:jbossorg_blog-resteasy_3_6_0_final_and_4_0_0_beta4</id><updated>2018-07-02T12:56:08Z</updated><published>2018-07-02T12:56:00Z</published><content type="html">&lt;!-- [DocumentBodyStart:8601afd5-5da4-4e10-b0d7-6bfd56eb8993] --&gt;&lt;div class="jive-rendered-content"&gt;&lt;p&gt;You might have recently read about the very interesting new features being developed these days in &lt;strong&gt;RESTEasy&lt;/strong&gt;... great, the time has come to &lt;em&gt;deliver them in a couple of releases!&lt;/em&gt;&lt;/p&gt;&lt;p&gt;Last week, &lt;strong&gt;RESTEasy 3.6.0.Final&lt;/strong&gt; and &lt;strong&gt;4.0.0.Beta4&lt;/strong&gt; have been tagged, built and published; here is a list of the most relevant additions coming with them:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;em&gt;client and server side reactive extensions&lt;/em&gt; [1][2]&lt;/li&gt;&lt;li&gt;&lt;em&gt;parameter annotations with default names&lt;/em&gt; [3][4]&lt;/li&gt;&lt;li&gt;&lt;em&gt;JettyClientEngine to use jetty-client with JAX-RS Client&lt;/em&gt; [5]&lt;/li&gt;&lt;li&gt;&lt;em&gt;SPI to modify resource metadata&lt;/em&gt; [6]&lt;/li&gt;&lt;/ul&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;Moreover, 4.0.0.Beta4, also feature the first part of the changes for the &lt;em&gt;tracing system&lt;/em&gt; [7] and &lt;em&gt;asynchronous container filters&lt;/em&gt; [8] support.&lt;/p&gt;&lt;p&gt;Both releases are available on the usual Maven repository, feel free to try them out!&lt;/p&gt;&lt;p&gt;3.6.0.Final is also being pulled into WildFly master, targetting inclusion in &lt;strong&gt;WildFly 14&lt;/strong&gt; release.&lt;/p&gt;&lt;p&gt;Enjoy!&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;[1] &lt;a class="jive-link-blog-small" data-containerId="1100" data-containerType="37" data-objectId="6190" data-objectType="38" href="https://developer.jboss.org/community/resteasy/blog/2018/06/04/asynchronous-reactive-rxjava-and-beyond"&gt;Asynchronous, reactive, rxjava and beyond!&lt;/a&gt; &lt;/p&gt;&lt;p&gt;[2] &lt;a class="jive-link-external-small" href="http://docs.jboss.org/resteasy/docs/3.6.0.Final/userguide/html/Reactive.html" rel="nofollow"&gt;Chapter 39. Reactive programming support&lt;/a&gt; &lt;/p&gt;&lt;p&gt;[3] &lt;a class="jive-link-blog-small" data-containerId="1100" data-containerType="37" data-objectId="6189" data-objectType="38" href="https://developer.jboss.org/community/resteasy/blog/2018/05/29/new-blog"&gt;New DRY-er annotations for parameters&lt;/a&gt; &lt;/p&gt;&lt;p&gt;[4] &lt;a class="jive-link-external-small" href="http://docs.jboss.org/resteasy/docs/3.6.0.Final/userguide/html/_NewParam.html" rel="nofollow"&gt;Chapter 13. Improved @&amp;hellip;Param annotations&lt;/a&gt; &lt;/p&gt;&lt;p&gt;[5] &lt;a class="jive-link-external-small" href="http://docs.jboss.org/resteasy/docs/3.6.0.Final/userguide/html/RESTEasy_Client_Framework.html#jetty_client" rel="nofollow"&gt;Chapter 50. RESTEasy Client API&lt;/a&gt; &lt;/p&gt;&lt;p&gt;[6] &lt;a class="jive-link-external-small" href="http://docs.jboss.org/resteasy/docs/3.6.0.Final/userguide/html/Resources_Metadata.html" rel="nofollow"&gt;Chapter 18. Resources metadata configuration&lt;/a&gt; &lt;/p&gt;&lt;p&gt;[7] &lt;a class="jive-link-blog-small" data-containerId="1100" data-containerType="37" data-objectId="6195" data-objectType="38" href="https://developer.jboss.org/community/resteasy/blog/2018/06/11/a-brief-introduction-to-the-resteasy-tracing-feature"&gt;A brief introduction to the RESTEasy Tracing Feature&lt;/a&gt; &lt;/p&gt;&lt;p&gt;[8] &lt;a class="jive-link-blog-small" data-containerId="1100" data-containerType="37" data-objectId="6198" data-objectType="38" href="https://developer.jboss.org/community/resteasy/blog/2018/06/18/new-asynchronous-container-filters"&gt;New: Asynchronous container filters&lt;/a&gt; &lt;/p&gt;&lt;/div&gt;&lt;!-- [DocumentBodyEnd:8601afd5-5da4-4e10-b0d7-6bfd56eb8993] --&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/Hbol_JezbYc" height="1" width="1" alt=""/&gt;</content><summary>You might have recently read about the very interesting new features being developed these days in RESTEasy... great, the time has come to deliver them in a couple of releases! Last week, RESTEasy 3.6.0.Final and 4.0.0.Beta4 have been tagged, built and published; here is a list of the most relevant additions coming with them: client and server side reactive extensions [1][2] parameter annotations ...</summary><dc:creator>Alessio Soldano</dc:creator><dc:date>2018-07-02T12:56:00Z</dc:date><feedburner:origLink>https://developer.jboss.org/community/resteasy/blog/2018/07/02/resteasy-360final-and-400beta4</feedburner:origLink></entry><entry><title>Hotrod clients C++ and C# 8.3.0.Alpha1 are out!</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/cDM6WFfAq-c/hotrod-clients-c-and-c-830alpha1-are-out.html" /><category term="alpha" scheme="searchisko:content:tags" /><category term="C#" scheme="searchisko:content:tags" /><category term="C++" scheme="searchisko:content:tags" /><category term="feed_group_name_infinispan" scheme="searchisko:content:tags" /><category term="feed_name_infinispan" scheme="searchisko:content:tags" /><category term="minor release" scheme="searchisko:content:tags" /><category term="release" scheme="searchisko:content:tags" /><author><name>rigazilla</name></author><id>searchisko:content:id:jbossorg_blog-hotrod_clients_c_and_c_8_3_0_alpha1_are_out</id><updated>2018-07-02T08:51:16Z</updated><published>2018-07-02T08:51:00Z</published><content type="html">Dear Infinispanners,&lt;br /&gt;&lt;br /&gt;The C++ and C# 8.3.0.Alpha1 releases are available!&lt;br /&gt;&lt;br /&gt;Both the clients come with these new features:&lt;br /&gt;&lt;ul&gt;&lt;li&gt;counter operations, to use cluster distributed counters [1]&lt;/li&gt;&lt;li&gt;admin operations, to create/remove cache programmatically at runtime [2] &lt;/li&gt;&lt;/ul&gt;For the .NET Core lovers, there's a work in progress to implement the dotnet core build for the C# client [3].&lt;br /&gt;Features list, code and bits are available as usual: [4] [5] [6].&lt;br /&gt;&lt;br /&gt;Cheers,&lt;br /&gt;The Infinispan Team&lt;br /&gt;&lt;br /&gt;[1]&lt;a href="http://infinispan.org/docs/stable/user_guide/user_guide.html#clustered_counters"&gt; Clustered Counters&lt;/a&gt;&lt;br /&gt;[2] &lt;a href="http://infinispan.org/docs/stable/user_guide/user_guide.html#hot_rod_admin_tasks"&gt;Hot Rod Admin Tasks&lt;/a&gt;&lt;br /&gt;[3] &lt;a href="https://github.com/infinispan/dotnet-client/blob/master/README.md"&gt;How to build à la .NET Core manière&lt;/a&gt;&lt;br /&gt;[4]&lt;a href="https://issues.jboss.org/secure/ReleaseNote.jspa?projectId=12314125&amp;amp;version=12337514"&gt; Release notes&lt;/a&gt;&lt;br /&gt;[5++] &lt;a href="https://github.com/infinispan/cpp-client/tree/8.3.0.Alpha1"&gt;C++ code for 8.3.0.Alpha1&lt;/a&gt;&lt;br /&gt;[5#] &lt;a href="https://github.com/infinispan/dotnet-client/tree/8.3.0.Alpha1https://github.com/infinispan/dotnet-client/tree/8.3.0.Alpha1"&gt;C# code for 8.3.0.Alpha1&lt;/a&gt;&lt;br /&gt;[6] &lt;a href="http://infinispan.org/hotrod-clients/"&gt;Downloads&lt;/a&gt;&lt;img src="http://feeds.feedburner.com/~r/Infinispan/~4/28xusWgGZWY" height="1" width="1" alt=""/&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/cDM6WFfAq-c" height="1" width="1" alt=""/&gt;</content><summary>Dear Infinispanners, The C++ and C# 8.3.0.Alpha1 releases are available! Both the clients come with these new features: counter operations, to use cluster distributed counters [1] admin operations, to create/remove cache programmatically at runtime [2] For the .NET Core lovers, there's a work in progress to implement the dotnet core build for the C# client [3]. Features list, code and bits are ava...</summary><dc:creator>rigazilla</dc:creator><dc:date>2018-07-02T08:51:00Z</dc:date><feedburner:origLink>http://feedproxy.google.com/~r/Infinispan/~3/28xusWgGZWY/hotrod-clients-c-and-c-830alpha1-are-out.html</feedburner:origLink></entry><entry><title>Why Kubernetes Is the New Application Server</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/NYgl-DiBQfI/" /><category term="ci/cd" scheme="searchisko:content:tags" /><category term="Containers" scheme="searchisko:content:tags" /><category term="devops" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="istio" scheme="searchisko:content:tags" /><category term="Kubernetes" scheme="searchisko:content:tags" /><category term="microprofile" scheme="searchisko:content:tags" /><category term="microservices" scheme="searchisko:content:tags" /><category term="Modern App Dev" scheme="searchisko:content:tags" /><category term="Red Hat OpenShift" scheme="searchisko:content:tags" /><category term="Red Hat OpenShift Application Runtimes" scheme="searchisko:content:tags" /><category term="Red Hat OpenShift Container Platform" scheme="searchisko:content:tags" /><category term="security" scheme="searchisko:content:tags" /><author><name>Rafael Benevides</name></author><id>searchisko:content:id:jbossorg_blog-why_kubernetes_is_the_new_application_server</id><updated>2018-06-28T11:00:34Z</updated><published>2018-06-28T11:00:34Z</published><content type="html">&lt;p&gt;Have you ever wondered why you are deploying your multi-platform applications using containers? Is it just a matter of “following the hype”? In this article, I&amp;#8217;m going to ask some provocative questions to make my case for &lt;em&gt;Why Kubernetes is the new application server&lt;/em&gt;.&lt;/p&gt; &lt;p&gt;You might have noticed that the majority of languages are interpreted and use “runtimes” to execute your source code. In theory, most Node.js, Python, and Ruby code can be easily moved from one platform (Windows, Mac, Linux) to another platform. Java applications go even further by having the compiled Java class turned into a bytecode, capable of running anywhere that has a JVM (Java Virtual Machine).&lt;/p&gt; &lt;p&gt;The Java ecosystem provides a standard format to distribute all Java classes that are part of the same application. You can package these classes as a JAR (Java Archive), WAR (Web Archive), and EAR (Enterprise Archive) that contains the front end, back end, and libraries embedded. So I ask you: Why do you use containers to distribute your Java application? Isn’t it already supposed to be easily portable between environments?&lt;/p&gt; &lt;p&gt;&lt;span id="more-495187"&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;Answering this question from a developer perspective isn&amp;#8217;t always obvious. But think for a moment about your development environment and some possible issues caused by the difference between it and the production environment:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Do you use Mac, Windows, or Linux? Have you ever faced an issue related to &lt;code&gt;\&lt;/code&gt; versus &lt;code&gt;/&lt;/code&gt; as the file path separator?&lt;/li&gt; &lt;li&gt;What version of JDK do you use? Do you use Java 10 in development, but production uses JRE 8? Have you faced any bugs introduced by  JVM differences?&lt;/li&gt; &lt;li&gt;What version of the application server do you use? Is the production environment using the same configuration, security patches, and library versions?&lt;/li&gt; &lt;li&gt;During production deployment, have you encountered a JDBC driver issue that you didn’t face in your development environment due to different versions of the driver or database server?&lt;/li&gt; &lt;li&gt;Have you ever asked the application server admin to create a datasource or a JMS queue and it had a typo?&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;All the issues above are caused by factors external to your application, and one of the greatest things about containers is that you can deploy everything (for example, a Linux distribution, the JVM, the application server, libraries, configurations and, finally, your application) inside a pre-built container. Plus, executing a single container that has everything built in is incredibly easier than moving your code to a production environment and trying to resolve the differences when it doesn&amp;#8217;t work. Since it’s easy to execute, it is also easy to scale the same container image to multiple replicas.&lt;/p&gt; &lt;h2&gt;Empowering Your Application&lt;/h2&gt; &lt;p&gt;Before containers became very popular, several &lt;a href="https://en.wikipedia.org/wiki/Non-functional_requirement#Examples"&gt;NFR (non-functional requirements)&lt;/a&gt; such as security, isolation, fault tolerance, configuration management, and others were provided by application servers. As an analogy, the application servers were planned to be to applications what CD (Compact Disc) players are to CDs.&lt;/p&gt; &lt;p&gt;As a developer, you would be responsible to follow a predefined standard and distribute the application in a specific format, while on the other hand the application server would “execute” your application and give additional capabilities that could vary from different “brands.”  Note: In the Java world, the standard for enterprise capabilities provided by an application server has recently moved under the Eclipse foundation. The work on Eclipse Enterprise for Java (&lt;a href="https://projects.eclipse.org/projects/ee4j"&gt;EE4J&lt;/a&gt;), has resulted in &lt;a href="https://jakarta.ee/"&gt;Jakarta EE&lt;/a&gt;.  (For more info, read the article &lt;a href="https://developers.redhat.com/blog/2018/04/24/jakarta-ee-is-officially-out/"&gt;&lt;em&gt;Jakarta EE is officially out&lt;/em&gt;&lt;/a&gt; or watch the &lt;a href="https://developers.redhat.com/videos/youtube/f2EwhTUmeOI/"&gt;DevNation video: &lt;em&gt;Jakarta EE: The future of Java EE&lt;/em&gt;&lt;/a&gt;.)&lt;/p&gt; &lt;p&gt;Following the same CD player analogy, with the ascension of containers, the &lt;a href="https://developers.redhat.com/blog/2018/02/22/container-terminology-practical-introduction/"&gt;&lt;em&gt;container image&lt;/em&gt;&lt;/a&gt; has become the new CD format. In fact, a container image is nothing more than a format for distributing your containers. (If you need to get a better handle on what container images are and how they are distributed see &lt;em&gt;&lt;a href="https://developers.redhat.com/blog/2018/02/22/container-terminology-practical-introduction/"&gt;A Practical Introduction to Container Terminology&lt;/a&gt;&lt;/em&gt;.)&lt;/p&gt; &lt;p&gt;The real benefits of containers happen when you need to add enterprise capabilities to your application. And the best way to provide these capabilities to a containerized application is by using Kubernetes as a platform for them. Additionally, the Kubernetes platform provides a great foundation for other projects such as &lt;a href="https://www.openshift.com/"&gt;Red Hat OpenShift&lt;/a&gt;, &lt;a href="https://istio.io/"&gt;Istio&lt;/a&gt;, and &lt;a href="https://openwhisk.apache.org/"&gt;Apache OpenWhisk&lt;/a&gt; to build on and make it easier to build and deploy robust production quality applications.&lt;/p&gt; &lt;p&gt;Let’s explore nine of these capabilities:&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/05/Screenshot-2018-05-18-21.20.31.png"&gt;&lt;img src="https://developers.redhat.com/blog/wp-content/uploads/2018/05/Screenshot-2018-05-18-21.20.31.png" alt="" width="1634" height="1254" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;h3&gt;1 – Service Discovery&lt;/h3&gt; &lt;p&gt;Service discovery is the process of figuring out how to connect to a service.  To get many of the benefits of containers and cloud-native applications, you need to remove configuration from your container images so you can use the same container image in all environments. Externalized configuration from applications is one of the key principles of the &lt;a href="https://developers.redhat.com/blog/2017/06/22/12-factors-to-cloud-success/"&gt;12-factor application&lt;/a&gt;. Service discovery is one of the ways to get configuration information from the runtime environment instead of it being hardcoded in the application. Kubernetes provides &lt;a href="https://kubernetes.io/docs/concepts/services-networking/service/#discovering-services"&gt;service discovery&lt;/a&gt; out of the box. Kubernetes also provides &lt;a href="https://kubernetes-v1-4.github.io/docs/user-guide/configmap/"&gt;ConfigMaps&lt;/a&gt; and &lt;a href="https://kubernetes.io/docs/concepts/configuration/secret/"&gt;Secrets&lt;/a&gt; for removing configuration from your application containers.  Secrets solve some of the challenges that arise when you need to store the credentials for connecting to a service like a database in your runtime environment.&lt;/p&gt; &lt;p&gt;With Kubernetes, there’s no need to use an external server or framework.  While you can manage the environment settings for each runtime environment through Kubernetes YAML files, Red Hat OpenShift provides a GUI and CLI that can make it easier for DevOps teams to manage.&lt;/p&gt; &lt;h3&gt;2 – Basic Invocation&lt;/h3&gt; &lt;p&gt;Applications running inside containers can be accessed through &lt;a href="https://kubernetes.io/docs/concepts/services-networking/ingress/"&gt;Ingress&lt;/a&gt; access— in other words, routes from the outside world to the service you are exposing. OpenShift provides &lt;a href="https://docs.openshift.com/container-platform/3.9/architecture/networking/routes.html#overview"&gt;route objects&lt;/a&gt; using HAProxy, which has several capabilities and load-balancing strategies.  You can use the routing capabilities to do rolling deployments. This can be the basis of some very sophisticated CI/CD strategies. See &amp;#8220;6 – Build and Deployment Pipelines&amp;#8221; below.&lt;/p&gt; &lt;p&gt;What if you need to run a one-time job, such as a batch process, or simply leverage the cluster to compute a result (such as computing the digits of Pi)? Kubernetes provides &lt;a href="https://kubernetes.io/docs/concepts/workloads/controllers/jobs-run-to-completion/"&gt;job objects&lt;/a&gt; for this use case. There is also a &lt;a href="https://kubernetes.io/docs/concepts/workloads/controllers/cron-jobs/"&gt;cron job&lt;/a&gt; that manages time-based jobs.&lt;/p&gt; &lt;h3&gt;3 – Elasticity&lt;/h3&gt; &lt;p&gt;Elasticity is solved in Kubernetes by using &lt;a href="https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/"&gt;ReplicaSets&lt;/a&gt; (which used to be called Replication Controllers). Just like most configurations for Kubernetes, a ReplicaSet is a way to reconcile a desired state: you tell Kubernetes what state the system should be in and Kubernetes figures out how to make it so. A ReplicaSet controls the number of replicas or exact copies of the app that should be running at any time.&lt;/p&gt; &lt;p&gt;But what happens when you build a service that is even more popular than you planned for and you run out of compute? You can use the Kubernetes &lt;a href="https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/#what-is-the-horizontal-pod-autoscaler"&gt;Horizontal Pod Autoscaler&lt;/a&gt;, which scales the number of pods based on observed CPU utilization (or, with &lt;a href="https://github.com/kubernetes/community/blob/master/contributors/design-proposals/instrumentation/custom-metrics-api.md"&gt;custom metrics&lt;/a&gt; support, on some other application-provided metrics).&lt;/p&gt; &lt;h3&gt;4 – Logging&lt;/h3&gt; &lt;p&gt;Since your Kubernetes cluster can and will run several replicas of your containerized application, it’s important that you aggregate these logs so they can be viewed in one place. Also, in order to utilize benefits like autoscaling (and other cloud-native capabilities), your containers need to be immutable. So you need to store your logs outside of your container so they will be persistent across runs. OpenShift allows you to deploy the EFK stack to aggregate logs from hosts and applications, whether they come from multiple containers or even from deleted pods.&lt;/p&gt; &lt;p&gt;The EFK stack is composed of:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://www.elastic.co/products/elasticsearch"&gt;Elasticsearch&lt;/a&gt; (ES), an object store where all logs are stored&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.fluentd.org/architecture"&gt;Fluentd&lt;/a&gt;, which gathers logs from nodes and feeds them to Elasticsearch&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.elastic.co/guide/en/kibana/current/introduction.html"&gt;Kibana&lt;/a&gt;, a web UI for Elasticsearch&lt;/li&gt; &lt;/ul&gt; &lt;h3&gt;5 – Monitoring&lt;/h3&gt; &lt;p&gt;Although logging and monitoring seem to solve the same problem, they are different from each other. Monitoring is observation, checking, often alerting, as well as recording. Logging is recording only.&lt;/p&gt; &lt;p&gt;&lt;a href="https://prometheus.io/"&gt;Prometheus&lt;/a&gt; is an open-source monitoring system that includes time series database. It can be used for storing and querying metrics, alerting, and using visualizations to gain insights into your systems. Prometheus is perhaps the most popular choice for monitoring Kubernetes clusters. On the &lt;a href="https://developers.redhat.com/blog/"&gt;Red Hat Developers blog&lt;/a&gt;, there are several articles covering monitoring using &lt;a href="https://developers.redhat.com/blog/tag/prometheus/"&gt;Prometheus&lt;/a&gt;. You can also find Prometheus articles on the &lt;a href="https://blog.openshift.com/tag/prometheus/"&gt;OpenShift blog&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;You can also see Prometheus in action together with Istio at &lt;a href="https://learn.openshift.com/servicemesh/3-monitoring-tracing"&gt;https://learn.openshift.com/servicemesh/3-monitoring-tracing&lt;/a&gt;.&lt;/p&gt; &lt;h3&gt;6 – Build and Deployment Pipelines&lt;/h3&gt; &lt;p&gt;CI/CD (Continuous Integration/Continuous Delivery) pipelines are not a strict “must have” requirement for your applications. However, CI/CD are often cited as pillars of successful software development and &lt;a href="https://devops.com/optimizing-effective-cicd-pipeline/"&gt;DevOps&lt;/a&gt; practices.  No software should be deployed into production without a CI/CD pipeline. The book &lt;a href="https://www.amazon.com/dp/0321601912?tag=contindelive-20"&gt;&lt;em&gt;Continuous Delivery: Reliable Software Releases through Build, Test, and Deployment Automation&lt;/em&gt;&lt;/a&gt;, by Jez Humble and David Farley, says this about CD: “Continuous Delivery is the ability to get changes of all types—including new features, configuration changes, bug fixes and experiments—into production, or into the hands of users, safely and quickly in a sustainable way.”&lt;/p&gt; &lt;p&gt;OpenShift provides CI/CD pipelines out of the box as a &amp;#8220;&lt;a href="https://docs.openshift.com/container-platform/3.7/dev_guide/builds/build_strategies.html#pipeline-strategy-options"&gt;build strategy&lt;/a&gt;.&amp;#8221; Check out &lt;a href="https://www.youtube.com/watch?v=N8R3-eNVoEc"&gt;this video&lt;/a&gt; that I recorded two years ago, which has an example of a Jenkins CI/CD pipeline that deploys a new microservice.&lt;/p&gt; &lt;h3&gt;7 – Resilience&lt;/h3&gt; &lt;p&gt;While Kubernetes provides resilience options for the &lt;a href="https://docs.openshift.com/container-platform/3.9/admin_guide/high_availability.html"&gt;cluster itself&lt;/a&gt;, it can also help the application be resilient by providing &lt;a href="https://kubernetes.io/docs/concepts/storage/persistent-volumes/"&gt;PersistentVolumes&lt;/a&gt; that support replicated volumes. Kubernetes&amp;#8217; &lt;a href="https://kubernetes.io/docs/concepts/workloads/controllers/replicationcontroller/"&gt;ReplicationControllers&lt;/a&gt;/deployments ensure that the specified numbers of pod replicas are consistently deployed across the cluster, which automatically handles any possible &lt;a href="https://kubernetes.io/docs/concepts/architecture/nodes/#what-is-a-node"&gt;node&lt;/a&gt; failure.&lt;/p&gt; &lt;p&gt;Together with resilience, fault tolerance serves as an effective means to address users&amp;#8217; reliability and availability concerns. Fault tolerance can also be provided to an application that is running on Kubernetes through &lt;a href="https://istio.io/"&gt;Istio&lt;/a&gt; by its retries rules, circuit breaker, and pool ejection. Do you want to see it for yourself? Try the Istio Circuit Breaker tutorial at &lt;a href="https://learn.openshift.com/servicemesh/7-circuit-breaker"&gt;https://learn.openshift.com/servicemesh/7-circuit-breaker&lt;/a&gt;.&lt;/p&gt; &lt;h3&gt;8 – Authentication&lt;/h3&gt; &lt;p&gt;Authentication in Kubernetes can also be provided by Istio through its &lt;a href="https://istio.io/docs/concepts/security/mutual-tls.html"&gt;mutual TLS authentication&lt;/a&gt;, which aims to enhance the security of microservices and their communication without requiring service code changes. It is responsible for:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Providing each service with a strong identity that represents its role to enable interoperability across clusters and clouds&lt;/li&gt; &lt;li&gt;Securing service-to-service communication and end user-to-service communication&lt;/li&gt; &lt;li&gt;Providing a key management system to automate key and certificate generation, distribution, rotation, and revocation&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Additionally, it is worth mentioning that you can also run &lt;a href="https://www.keycloak.org/"&gt;Keycloak&lt;/a&gt; inside a Kubernetes/OpenShift cluster to provide both authentication and authorization. Keycloak is the upstream product for Red Hat Single Sign-on. For more information, read &lt;a href="https://developers.redhat.com/blog/tag/keycloak/"&gt;Single-Sign On Made Easy with Keycloak&lt;/a&gt;. If you are using Spring Boot, watch the DevNation video: &lt;a href="https://developers.redhat.com/videos/youtube/Bdg_DjuoX0A/"&gt;Secure Spring Boot Microservices with Keycloak&lt;/a&gt; or &lt;a href="https://developers.redhat.com/blog/tag/keycloak/"&gt;read the blog article&lt;/a&gt;.&lt;/p&gt; &lt;h3&gt;9 – Tracing&lt;/h3&gt; &lt;p&gt;Istio-enabled applications can be configured to collect trace spans using &lt;a href="https://zipkin.io/"&gt;Zipkin&lt;/a&gt; or &lt;a href="https://www.jaegertracing.io/docs/"&gt;Jaeger&lt;/a&gt;. Regardless of what language, framework, or platform you use to build your application, Istio can enable distributed tracing. Check it out at &lt;a href="https://learn.openshift.com/servicemesh/3-monitoring-tracing"&gt;https://learn.openshift.com/servicemesh/3-monitoring-tracing&lt;/a&gt;.  See also &lt;a href="https://developers.redhat.com/blog/2018/05/08/getting-started-with-istio-and-jaeger-on-your-laptop/"&gt;Getting Started with Istio and Jaeger on your laptop&lt;/a&gt; and the recent DevNation video: &lt;a href="https://developers.redhat.com/blog/2018/06/20/next-devnation-live-advanced-microservices-tracing-with-jaeger-june-21st-12pm-edt/"&gt;Advanced microservices tracing with Jaeger&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Are Application Servers Dead?&lt;/h2&gt; &lt;p&gt;Going through these capabilities, you can realize how Kubernetes + OpenShift + Istio can really empower your application and provide features that used to be the responsibility of an application server or a software framework such as &lt;a href="https://netflix.github.io/"&gt;Netflix OSS&lt;/a&gt;. Does that mean application servers are dead?&lt;/p&gt; &lt;p&gt;In this new containerized world, application servers are mutating into becoming more like frameworks. It&amp;#8217;s natural that the evolution of software development caused the evolution of application servers. A great example of this evolution is the &lt;a href="http://microprofile.io/"&gt;Eclipse MicroProfile&lt;/a&gt; specification having &lt;a href="http://wildfly-swarm.io"&gt;WildFly Swarm&lt;/a&gt; as the application server, which provides to the developer features such as fault tolerance, configuration, tracing, REST (client and server), and so on. However, WildFly Swarm and the MicroProfile specification are designed to be very lightweight. WildFly Swarm doesn&amp;#8217;t have the vast array of components required by a full Java enterprise application server. Instead, it focuses on microservices and having just enough of the application server to build and run your application as a simple executable .jar file.  You can read more about &lt;a href="https://developers.redhat.com/blog/tag/microprofile/"&gt;MicroProfile&lt;/a&gt; on this blog.&lt;/p&gt; &lt;p&gt;Furthermore, Java applications can have features such as the Servlet engine, a datasource pool, dependency injection, transactions, messaging, and so forth. Of course, frameworks can provide these features, but an application server must also have everything you need to build, run, deploy, and manage enterprise applications in any environment, regardless of whether they are inside containers. In fact, application servers can be executed anywhere, for instance, on bare metal, on virtualization platforms such as &lt;a href="https://www.redhat.com/en/technologies/virtualization/enterprise-virtualization"&gt;Red Hat Virtualization&lt;/a&gt;, on private cloud environments such as &lt;a href="https://www.openstack.org/"&gt;Red Hat OpenStack Platform&lt;/a&gt;, and also on public cloud environments such as &lt;a href="https://azure.microsoft.com/en-us/"&gt;Microsoft Azure&lt;/a&gt; or &lt;a href="https://aws.amazon.com/"&gt;Amazon Web Services&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;A good application server ensures consistency between the APIs that are provided and their implementations. Developers can be sure that deploying their business logic, which requires certain capabilities, will work because the application server developers (and the defined standards) have ensured that these components work together and have evolved together. Furthermore, a good application server is also responsible for maximizing throughput and scalability, because it will handle all the requests from the users; having reduced latency and improved load times, because it will help your application&amp;#8217;s &lt;a href="https://12factor.net/disposability"&gt;disposability&lt;/a&gt;; be lightweight with a small footprint that minimizes hardware resources and costs; and finally, be secure enough to avoid any security breach. For Java developers, Red Hat provides &lt;a href="https://www.redhat.com/en/technologies/jboss-middleware/application-platform"&gt;Red Hat JBoss Enterprise Application Platform&lt;/a&gt;, which fulfills all the requirements of a modern, modular application server.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;Container images have become the standard packaging format to distribute cloud-native applications. While containers “per se” don’t provide real business advantages to applications, Kubernetes and its related projects, such as OpenShift and Istio, provide the non-functional requirements that used to be part of an application server.&lt;/p&gt; &lt;p&gt;Most of these non-functional requirements that developers used to get from an application server or from a library such as &lt;a href="https://netflix.github.io/"&gt;Netflix OSS&lt;/a&gt; were bound to a specific language, for example, Java. On the other hand, when developers choose to meet these requirements using Kubernetes + OpenShift + Istio, they are not attached to any specific language, which can encourage the use of the best technology/language for each use case.&lt;/p&gt; &lt;p&gt;Finally, application servers still have their place in software development. However, they are mutating into becoming more like language-specific frameworks that are a great shortcut when developing applications, since they contain lots of already written and tested functionality.&lt;/p&gt; &lt;p&gt;One of the best things about moving to containers, Kubernetes, and microservices is that you don&amp;#8217;t have to choose a single application server, framework, architectural style or even language for your application. You can easily deploy a container with JBoss EAP running your existing Java EE application, alongside other containers that have new microservices using Wildfly Swarm, or Eclipse Vert.x for reactive programming. These containers can all be managed through Kubernetes. To see this concept in action, take a look at &lt;a href="https://developers.redhat.com/products/rhoar/overview/"&gt;Red Hat OpenShift Application Runtimes&lt;/a&gt;. Use the &lt;a href="https://developers.redhat.com/launch/"&gt;Launch service&lt;/a&gt; to build and deploy a sample app online using WildFly Swarm, Vert.x, Spring Boot, or Node.js. Select the Externalized Configuration mission to learn how to use Kubernetes ConfigMaps. This will get you started on your path to cloud-native applications.&lt;/p&gt; &lt;p&gt;You can say that &lt;a href="https://www.linkedin.com/pulse/openshift-new-enterprise-linux-daniel-riek/"&gt;Kubernetes/OpenShift is the new Linux&lt;/a&gt; or even that &amp;#8220;Kubernetes is the new application server.&amp;#8221; But the fact is that an application server/runtime + OpenShift/Kubernetes + Istio has become the &amp;#8220;de facto&amp;#8221; cloud-native application platform!&lt;/p&gt; &lt;hr /&gt; &lt;p&gt;If you haven&amp;#8217;t been to the Red Hat Developer site lately, you should check out the pages on:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/topics/kubernetes/"&gt;Kubernetes and container management&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/topics/microservices/"&gt;Microservices&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/topics/service-mesh/"&gt;Service mesh and Istio&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;a name="rbenevides"&gt;&lt;/a&gt;&lt;/p&gt; &lt;div class="author"&gt; &lt;p&gt;&lt;img class="author-photo alignleft" title="Rafael" src="http://rafabene.com/images/rafaelbenevides.jpg" alt="Rafael Benevides" width="119" height="119" /&gt;&lt;/p&gt; &lt;h3&gt;About the author:&lt;/h3&gt; &lt;p&gt;Rafael Benevides is Director of Developer Experience at &lt;a href="http://www.redhat.com"&gt;Red Hat&lt;/a&gt;. With many years of experience in several fields of the IT industry, he helps developers and companies all over the world to be more effective in software development. Rafael considers himself a problem solver who has a big love for sharing. He is a member of Apache DeltaSpike PMC—a Duke’s Choice Award winner project—and a speaker in conferences such as JavaOne, Devoxx, TDC, DevNexus, and many others.| &lt;a href="https://www.linkedin.com/in/rafaelbenevides" target="_blank" rel="noopener"&gt;LinkedIn&lt;/a&gt; | &lt;a href="http://rafabene.com/" target="_blank" rel="noopener"&gt;rafabene.com&lt;/a&gt;&lt;/p&gt; &lt;/div&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F06%2F28%2Fwhy-kubernetes-is-the-new-application-server%2F&amp;#38;linkname=Why%20Kubernetes%20is%20The%20New%20Application%20Server" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F06%2F28%2Fwhy-kubernetes-is-the-new-application-server%2F&amp;#38;linkname=Why%20Kubernetes%20is%20The%20New%20Application%20Server" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F06%2F28%2Fwhy-kubernetes-is-the-new-application-server%2F&amp;#38;linkname=Why%20Kubernetes%20is%20The%20New%20Application%20Server" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F06%2F28%2Fwhy-kubernetes-is-the-new-application-server%2F&amp;#38;linkname=Why%20Kubernetes%20is%20The%20New%20Application%20Server" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F06%2F28%2Fwhy-kubernetes-is-the-new-application-server%2F&amp;#38;linkname=Why%20Kubernetes%20is%20The%20New%20Application%20Server" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F06%2F28%2Fwhy-kubernetes-is-the-new-application-server%2F&amp;#38;linkname=Why%20Kubernetes%20is%20The%20New%20Application%20Server" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F06%2F28%2Fwhy-kubernetes-is-the-new-application-server%2F&amp;#38;linkname=Why%20Kubernetes%20is%20The%20New%20Application%20Server" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F06%2F28%2Fwhy-kubernetes-is-the-new-application-server%2F&amp;#38;linkname=Why%20Kubernetes%20is%20The%20New%20Application%20Server" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F06%2F28%2Fwhy-kubernetes-is-the-new-application-server%2F&amp;#38;title=Why%20Kubernetes%20is%20The%20New%20Application%20Server" data-a2a-url="https://developers.redhat.com/blog/2018/06/28/why-kubernetes-is-the-new-application-server/" data-a2a-title="Why Kubernetes is The New Application Server"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/06/28/why-kubernetes-is-the-new-application-server/"&gt;Why Kubernetes is The New Application Server&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/NYgl-DiBQfI" height="1" width="1" alt=""/&gt;</content><summary>Have you ever wondered why you are deploying your multi-platform applications using containers? Is it just a matter of “following the hype”? In this article, I’m going to ask some provocative questions to make my case for Why Kubernetes is the new application server. You might have noticed that the majority of languages are interpreted and use “runtimes” to execute your source code. In theory, mos...</summary><dc:creator>Rafael Benevides</dc:creator><dc:date>2018-06-28T11:00:34Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2018/06/28/why-kubernetes-is-the-new-application-server/</feedburner:origLink></entry><entry><title>Narayana Commit Markable Resource: a faultless LRCO for JDBC datasources</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/qq44hyr6kbA/narayana-commit-markable-resource.html" /><category term="feed_group_name_jbosstransactions" scheme="searchisko:content:tags" /><category term="feed_name_transactions" scheme="searchisko:content:tags" /><author><name>Ondřej Chaloupka</name></author><id>searchisko:content:id:jbossorg_blog-narayana_commit_markable_resource_a_faultless_lrco_for_jdbc_datasources</id><updated>2018-06-28T06:11:15Z</updated><published>2018-06-28T05:17:00Z</published><content type="html">&lt;p&gt; CMR is neat Narayana feature enabling full XA transaction capability for one non-XA JDBC resource. This gives you a way to engage a database resource to XA transaction even the JDBC driver is not fully XA capable (or you just have a design restriction on it) while transaction data consistency is kept. &lt;/p&gt; &lt;h2&gt;Last resource commit optimization (aka. LRCO)&lt;/h2&gt; &lt;p&gt; Maybe you will say "&lt;i&gt;adding one non-XA resource to a transaction is well-known LRCO optimization&lt;/i&gt;". And you are right. But just partially. The last resource commit optimization (abbreviated as LRCO) provides a way to enlist and process one non-XA datasource to the global transaction managed by the transaction manager. But LRCO contains a pitfall. When the crash of the system (or the connection) happens in particular point of the time, &lt;a href="https://developer.jboss.org/wiki/TwoPhaseCommit2PC"&gt;during two-phase commit processing&lt;/a&gt;, it causes data inconsistency. Namely, the LRCO could be committed while the rest of the resources will be rolled-back. &lt;/p&gt;&lt;p&gt; Let's elaborate a bit on the LRCO failure. Let's say we have a JMS resource where we send a message to a message broker and non-XA JDBC datasource where we save information to the database. &lt;p&gt; &lt;p&gt; &lt;i&gt;NOTE: The example refers to the Narayana two-phase commit implemenation.&lt;/i&gt; &lt;br/&gt;&lt;br/&gt; &lt;ol&gt; &lt;li&gt;updating the database with &lt;code&gt;INSERT INTO&lt;/code&gt; SQL command, enlisting LRCO resource under the transaction&lt;/li&gt; &lt;li&gt;sending a message to the JMS broker, enlisting the JMS resource to the transaction&lt;/li&gt; &lt;li&gt;Narayana starts the two phase commit processing&lt;/li&gt; &lt;li&gt;&lt;code&gt;prepare&lt;/code&gt; is called to JMS XA resource, the transaction log is stored at the JMS broker side&lt;/li&gt; &lt;li&gt;&lt;code&gt;prepare&lt;/code&gt; phase for the LRCO means to call &lt;code&gt;commit&lt;/code&gt; at the non-XA datasource. That call makes the data changes visible to the outer world.&lt;/li&gt; &lt;li&gt;crash of the Narayana JVM occurs before the Narayana can preserve information of commit to its transaction log store&lt;/li&gt; &lt;li&gt;after the Narayana restarts there is no notion about the existence of any transaction thus the prepared JMS resource is rolled-back during transaction recovery&lt;/li&gt; &lt;/ol&gt; &lt;p&gt; &lt;i&gt;Note:&lt;/i&gt; roll-backing of the JMS resource is caused by &lt;a href="http://narayana.io//docs/product/index.html#two-phase-variants"&gt;presumed abort strategy&lt;/a&gt; applied in the Narayana. If transaction manager does do not apply the presumed abort then you end ideally not better than in the &lt;a href="http://jbossts.blogspot.com/2011/03/heuristics-and-why-you-need-to-know.html"&gt;transaction heuristic state&lt;/a&gt;. &lt;/p&gt;&lt;/p&gt; &lt;p&gt; The LRCO processing is about ordering the LRCO resource as the last during the &lt;a href="https://developer.jboss.org/wiki/TwoPhaseCommit2PC"&gt;transaction manager 2PC&lt;/a&gt; &lt;code&gt;prepare&lt;/code&gt; phase. At place where transaction normally calls &lt;code&gt;prepare&lt;/code&gt; at &lt;code&gt;XAResource&lt;/code&gt;s there is called &lt;code&gt;commit&lt;/code&gt; at the LRCO's underlaying non-XA resource. &lt;br/&gt; Then during the transaction manager &lt;code&gt;commit&lt;/code&gt; phase there is called nothing for the LRCO. &lt;/p&gt; &lt;h2&gt;Commit markable resource (aka. CMR)&lt;/h2&gt;&lt;p&gt; The Commit Markable Resource, abbreviated as &lt;code&gt;CMR&lt;/code&gt;, is an enhancement of the last resource commit optimization applicable on the JDBC resources. The CMR approach achieves capabilities similar to XA by demanding special database table (normally named &lt;code&gt;xids&lt;/code&gt;) that is accessible for transaction manager to write and to read via the configured CMR datasource. &lt;/p&gt; &lt;p&gt; Let's demonstrate the CMR behavior at the example (reusing setup from the previous one). &lt;ol&gt; &lt;li&gt;updating the database with &lt;code&gt;INSERT INTO&lt;/code&gt; SQL command, enlisting the CMR resource under the transaction&lt;/li&gt; &lt;li&gt;sending a message to the JMS broker, enlisting the JMS resource to the transaction&lt;/li&gt; &lt;li&gt;Narayana starts the two phase commit processing&lt;/li&gt; &lt;li&gt;&lt;code&gt;prepare&lt;/code&gt; on CMR saves information about prepare to the &lt;code&gt;xids&lt;/code&gt; table&lt;/li&gt; &lt;li&gt;&lt;code&gt;prepare&lt;/code&gt; is called to JMS XA resource, the transaction log is stored at the JMS broker side&lt;/li&gt; &lt;li&gt;&lt;code&gt;commit&lt;/code&gt; on CMR means calling commit on underlaying non-XA datasource&lt;/li&gt; &lt;li&gt;&lt;code&gt;commit&lt;/code&gt; on JMS XA resource means commit on the XA JMS resource and thus the message being visible at the queue, the proper transaction log is removed at the JMS broker side&lt;/li&gt; &lt;li&gt;Narayana two phase commit processing ends&lt;/li&gt; &lt;/ol&gt;&lt;/p&gt; &lt;p&gt; From what you can see here the difference from the LRCO example is that the CMR resource is not ordered as last in the resource processing but it's ordered as the first one. The CMR prepare does not mean committing the work as in case of the LRCO but it means saving information about that CMR is considered to be prepared into the database &lt;code&gt;xids&lt;/code&gt; table. &lt;br/&gt; As the CMR is ordered as the first resource for processing it's taken as first during the commit phase too. The commit call then means to call &lt;code&gt;commit&lt;/code&gt; at the underlying database connection. The &lt;code&gt;xids&lt;/code&gt; table is not cleaned at that phase and it's normally responsibility of &lt;code&gt;CommitMarkableResourceRecordRecoveryModule&lt;/code&gt; to process the garbage collection of records in the &lt;code&gt;xids&lt;/code&gt; table (see more below). &lt;/p&gt; &lt;p&gt; The main fact to understand is that CMR resource is considered as &lt;i&gt;fully prepared&lt;/i&gt; only after the &lt;code&gt;commit&lt;/code&gt; is processed (meaning commit on the underlaying non-XA JDBC datasource). Till that time the transaction is considered as &lt;b&gt;not&lt;/b&gt; prepared and will be processed with rollback by the transaction recovery. &lt;/p&gt; &lt;p&gt; &lt;i&gt;NOTE:&lt;/i&gt; the term &lt;i&gt;fully prepared&lt;/i&gt; considers the standard XA two-phase commit processing. If the transaction manager finishes with the &lt;code&gt;prepare&lt;/code&gt; phase, aka. prepare is called on all transaction participants, the transaction is counted as prepared and &lt;code&gt;commit&lt;/code&gt; is expected to be called on each participant. &lt;/p&gt; &lt;p&gt; It's important to note that the correct processing of failures in transactions which contain CMR resources is responsibility of the special &lt;a href="https://jbossts.blogspot.com/2018/01/narayana-periodic-recovery-of-xa.html"&gt;periodic recovery module&lt;/a&gt; &lt;code&gt;CommitMarkableResourceRecordRecoveryModule&lt;/code&gt;. It has to be configured as &lt;b&gt;the first&lt;/b&gt; in the recovery module list as it needs to check and eventually process all the XA resources belonging to the transaction which contains the CMR resource (the recovery modules are processed in the order they were configured). You can check &lt;a href="https://github.com/wildfly/wildfly/blob/13.0.0.Final/transactions/src/main/java/org/jboss/as/txn/service/ArjunaRecoveryManagerService.java#L104"&gt;here how this is set up in WildFly&lt;/a&gt;. &lt;br/&gt; The CMR recovery module knows about the existence of the CMR resource from the record saved in the &lt;code&gt;xids&lt;/code&gt; table. From that it's capable to pair all the resources belonging to the same transaction where CMR was involved. &lt;/p&gt; &lt;h4&gt;xids: database table to save CMR processing data&lt;/h4&gt; &lt;p&gt; As said Narayana needs a special database table (usually named &lt;code&gt;xids&lt;/code&gt;) to save information that CMR was prepared. You may wonder what is content of that table. &lt;br/&gt; The table consists of three columns. &lt;ul&gt; &lt;li&gt;&lt;i&gt;xid&lt;/i&gt; : id of the transaction branch belonging to the CMR resource&lt;/li&gt; &lt;li&gt;&lt;i&gt;transactionManagerID&lt;/i&gt; : id of transaction manager, this serves to distinguish more transaction managers (WildFly servers) working with the same database. There is a strict rule that each transaction manager must be defined with unique transaction id (&lt;a href="https://wildscribe.github.io/WildFly/13.0/subsystem/transactions/index.html"&gt;see description of the node-identifer&lt;/a&gt;).&lt;/li&gt; &lt;li&gt;&lt;i&gt;actionuid&lt;/i&gt; : global transaction id which unites all the resources belonging to the one particular transaction&lt;/li&gt; &lt;/ul&gt;&lt;/p&gt; &lt;h4&gt;LRCO failure case with CMR&lt;/h4&gt; &lt;p&gt; In the example, we presented as problematic for LRCO, the container crashed just before prepare phase finished. In such case, the CMR is not committed yet. The other transaction participants are then rolled-back as the transaction was not &lt;i&gt;fully prepared&lt;/i&gt;. The CMR brings the consistent rollback outcome for all the resources. &lt;/p&gt; &lt;h2&gt;Commit markable resource configured in WildFly&lt;/h2&gt; &lt;p&gt; We have sketched the principle of the CMR and now it's time to check how to configure it for your application running at the &lt;a href="http://wildfly.org"&gt;WildFly&lt;/a&gt; application server. &lt;br/&gt; The configuration consists of three steps. &lt;ol&gt; &lt;li&gt;The JDBC datasource needs to be marked as &lt;i&gt;connectable&lt;/i&gt;&lt;/li&gt; &lt;li&gt;The database, the connectable datasource points to, has to be enriched with the &lt;code&gt;xids&lt;/code&gt; table where Narayana can saves the data about CMR processing&lt;/li&gt; &lt;li&gt;Transaction subsystem needs to be configured to be aware of the CMR capable resource&lt;/li&gt; &lt;/ol&gt;&lt;/p&gt; &lt;p&gt; In our example, I use the H2 database as it's good for the showcase. You can find it in quickstart I prepared too. Check out the &lt;a href="https://github.com/jbosstm/quickstart/tree/master/wildfly/commit-markable-resource"&gt; https://github.com/jbosstm/quickstart/tree/master/wildfly/commit-markable-resource&lt;/a&gt;. &lt;/p&gt; &lt;h3&gt;Mark JDBC datasource as connectable&lt;/h3&gt; &lt;p&gt; You will mark the resource as &lt;code&gt;connectable&lt;/code&gt; when you use attribute &lt;code&gt;connectable="true"&lt;/code&gt; in your datasource declaration in &lt;code&gt;standalone*.xml&lt;/code&gt; configuration file. When you use jboss cli for the app server configuration you will use commands &lt;/p&gt; &lt;pre&gt;&lt;code class="bash"&gt;/subsystem=datasources/data-source=jdbc-cmr:write-attribute(name=connectable, value=true)&lt;br /&gt;:reload&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt; The whole datasource configuration then looks like &lt;/p&gt; &lt;pre&gt;&lt;code class="xml"&gt;&amp;lt;datasource jndi-name="java:jboss/datasources/jdbc-cmr" pool-name="jdbc-cmr-datasource"&lt;br /&gt; enabled="true" use-java-context="true" connectable="true"&amp;gt;&lt;br /&gt; &amp;lt;connection-url&amp;gt;jdbc:h2:mem:cmrdatasource&amp;lt;/connection-url&amp;gt;&lt;br /&gt; &amp;lt;driver&amp;gt;h2&amp;lt;/driver&amp;gt;&lt;br /&gt; &amp;lt;security&amp;gt;&lt;br /&gt; &amp;lt;user-name&amp;gt;sa&amp;lt;/user-name&amp;gt;&lt;br /&gt; &amp;lt;password&amp;gt;sa&amp;lt;/password&amp;gt;&lt;br /&gt; &amp;lt;/security&amp;gt;&lt;br /&gt;&amp;lt;/datasource&amp;gt;&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt; When datasource is marked as connectable then the IronJacamar (JCA layer of WildFly) creates the datasource instance as implementing &lt;a href="https://github.com/ochaloup/jboss-transaction-spi/blob/master/src/main/java/org/jboss/tm/ConnectableResource.java"&gt;&lt;code&gt;org.jboss.tm.ConnectableResource&lt;/code&gt;&lt;/a&gt; (defined in the &lt;a href="https://github.com/ochaloup/jboss-transaction-spi"&gt;jboss-transaction-spi project&lt;/a&gt;). This resource defines that the class provides method &lt;code&gt;getConnection() throws Throwable&lt;/code&gt;. That's how the transaction manager is capable to obtain the connection to the database and works with the &lt;code&gt;xids&lt;/code&gt; table inside it. &lt;/p&gt; &lt;h3&gt;Xids database table creation&lt;/h3&gt; &lt;p&gt; The database configured to be &lt;code&gt;connectable&lt;/code&gt; has to ensure existence of the &lt;code&gt;xids&lt;/code&gt; before transaction manager starts. As described above the &lt;code&gt;xids&lt;/code&gt; allows to save the cruical information about the non-XA datasource during prepare. The shape of the SQL command depends on the SQL syntax of the database you use. The example of the &lt;a href="https://github.com/jbosstm/narayana/blob/5.8.2.Final/ArjunaJTA/jta/classes/com/arjuna/ats/internal/jta/resources/arjunacore/CommitMarkableResourceRecord.java#L74"&gt; table cleation commands is (see more commands under this link)&lt;/a&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="sql"&gt;-- Oracle&lt;br /&gt;CREATE TABLE xids (&lt;br /&gt; xid RAW(144), transactionManagerID VARCHAR(64), actionuid RAW(28)&lt;br /&gt;);&lt;br /&gt;CREATE UNIQUE INDEX index_xid ON xids (xid);&lt;br /&gt;&lt;br /&gt;-- PostgreSQL&lt;br /&gt;CREATE TABLE xids (&lt;br /&gt; xid bytea, transactionManagerID varchar(64), actionuid bytea&lt;br /&gt;);&lt;br /&gt;CREATE UNIQUE INDEX index_xid ON xids (xid);&lt;br /&gt;&lt;br /&gt;-- H2&lt;br /&gt;CREATE TABLE xids (&lt;br /&gt; xid VARBINARY(144), transactionManagerID VARCHAR(64), actionuid VARBINARY(28)&lt;br /&gt;);&lt;br /&gt;CREATE UNIQUE INDEX index_xid ON xids (xid);&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt; I addressed the need of the table definition in &lt;a href="https://github.com/jbosstm/quickstart/tree/master/wildfly/commit-markable-resource"&gt;the CMR quickstart&lt;/a&gt; by adding the JPA schema generation create script which contains &lt;a href="https://github.com/jbosstm/quickstart/blob/master/wildfly/commit-markable-resource/src/main/resources/META-INF/persistence.xml#L44"&gt;the SQL to initialize the database&lt;/a&gt;. &lt;/p&gt; &lt;h3&gt;Transaction manager CMR configuration&lt;/h3&gt; &lt;p&gt; The last part is to configure the CMR for the transaction subsystem. The declaration puts the datasource under the list &lt;a href="https://github.com/jbosstm/narayana/blob/5.8.2.Final/ArjunaJTA/jta/classes/com/arjuna/ats/jta/common/JTAEnvironmentBean.java#L104"&gt;JTAEnvironmentBean#commitMarkableResourceJNDINames&lt;/a&gt; which is then used in code of &lt;a href="https://github.com/jbosstm/narayana/blob/5.8.2.Final/ArjunaJTA/jta/classes/com/arjuna/ats/internal/jta/transaction/arjunacore/TransactionImple.java#L798"&gt;TransactionImple#createResource&lt;/a&gt;. &lt;br/&gt; The xml element used in the transaction subsystem and the jboss cli commands look like &lt;/p&gt; &lt;pre&gt;&lt;code class="xml"&gt;&amp;lt;commit-markable-resources&amp;gt;&lt;br /&gt; &amp;lt;commit-markable-resource jndi-name="java:jboss/datasources/jdbc-cmr"/&amp;gt;&lt;br /&gt;&amp;lt;/commit-markable-resources&amp;gt;&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt; &lt;pre&gt;&lt;code class="bash"&gt;/subsystem=transactions/commit-markable-resource="java:jboss/datasources/jdbc-cmr":add()&lt;br /&gt;:reload&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt; &lt;h4&gt;CMR configuration options&lt;/h4&gt; &lt;p&gt; In addition to such simple CMR declaration, the CMR can be configured with following parameters &lt;/p&gt; &lt;p&gt; &lt;ul&gt; &lt;li&gt;&lt;b&gt;jndi-name&lt;/b&gt; : as it could be seen above the jndi-name is way to point to the datasource which we mark as CMR ready&lt;/li&gt; &lt;li&gt;&lt;b&gt;name&lt;/b&gt; : defines the name of the table which is used for storing the CMR state during prepare while used during recovery. &lt;br/&gt;The default value (and we've reffered to it in this way above) is &lt;code&gt;xids&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;b&gt;immediate-cleanup&lt;/b&gt; : If configured to true then there is registered &lt;a href="https://github.com/jbosstm/narayana/blob/5.8.2.Final/ArjunaJTA/jta/classes/com/arjuna/ats/internal/jta/resources/arjunacore/CommitMarkableResourceRecord.java#L191"&gt;a synchronization&lt;/a&gt; which removes proper value from the &lt;code&gt;xids&lt;/code&gt; table immediatelly after the transaction is committed. &lt;br/&gt; When synchronization is not set up then the clean-up of the &lt;code&gt;xids&lt;/code&gt; table is responsibility of the recovery by the code at &lt;a href="https://github.com/jbosstm/narayana/blob/5.8.2.Final/ArjunaJTA/jta/classes/com/arjuna/ats/internal/jta/recovery/arjunacore/CommitMarkableResourceRecordRecoveryModule.java#L76"&gt;&lt;code&gt;CommitMarkableResourceRecordRecoveryModule&lt;/code&gt;&lt;/a&gt;. It checks about finished xids and it removes those which are free for garbage collection. &lt;br/&gt;The default value is &lt;code&gt;false&lt;/code&gt; (using only recovery garbage collection).&lt;/li&gt; &lt;li&gt;&lt;b&gt;batch-size&lt;/b&gt; : This parameter influences the process of the garbage collection (as described above). The garbage collection takes finished xids and runs &lt;code&gt;DELETE&lt;/code&gt; SQL command. The &lt;code&gt;DELETE&lt;/code&gt; contains the &lt;code&gt;WHERE xid in (...)&lt;/code&gt; clause with maximum of &lt;code&gt;batch-size&lt;/code&gt; entries provided. When there is still some finished xids left after deletion, another SQL command is assembled with maximum number of &lt;code&gt;batch-size&lt;/code&gt; entries again. &lt;br/&gt;The default value is &lt;code&gt;100&lt;/code&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;br/&gt; The &lt;code&gt;commit-markable-resource&lt;/code&gt; xml element configured with all the parameters looks like &lt;/p&gt; &lt;pre&gt;&lt;code class="xml"&gt;&amp;lt;subsystem xmlns="urn:jboss:domain:transactions:4.0"&amp;gt;&lt;br /&gt; &amp;lt;core-environment&amp;gt;&lt;br /&gt; &amp;lt;process-id&amp;gt;&lt;br /&gt; &amp;lt;uuid/&amp;gt;&lt;br /&gt; &amp;lt;/process-id&amp;gt;&lt;br /&gt; &amp;lt;/core-environment&amp;gt;&lt;br /&gt; &amp;lt;recovery-environment socket-binding="txn-recovery-environment" status-socket-binding="txn-status-manager"/&amp;gt;&lt;br /&gt; &amp;lt;object-store path="tx-object-store" relative-to="jboss.server.data.dir"/&amp;gt;&lt;br /&gt; &amp;lt;commit-markable-resources&amp;gt;&lt;br /&gt; &amp;lt;commit-markable-resource jndi-name="java:jboss/datasources/jdbc-cmr"&amp;gt;&lt;br /&gt; &amp;lt;xid-location name="myxidstable" batch-size="10" immediate-cleanup="true"/&amp;gt;&lt;br /&gt; &amp;lt;/commit-markable-resource&amp;gt;&lt;br /&gt; &amp;lt;/commit-markable-resources&amp;gt;&lt;br /&gt;&amp;lt;/subsystem&amp;gt;&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;And the jboss cli commands for the same are&lt;/p&gt; &lt;pre&gt;&lt;code class="bash"&gt;/subsystem=transactions/commit-markable-resource="java:jboss/datasources/jdbc-cmr"\&lt;br /&gt; :write-attribute(name=name, value=myxidstable)&lt;br /&gt; /subsystem=transactions/commit-markable-resource="java:jboss/datasources/jdbc-cmr"\&lt;br /&gt; :write-attribute(name=immediate-cleanup, value=true)&lt;br /&gt;/subsystem=transactions/commit-markable-resource="java:jboss/datasources/jdbc-cmr"\&lt;br /&gt; :write-attribute(name=batch-size, value=10)&lt;br /&gt;:reload&lt;br /&gt;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt; &lt;i&gt;NOTE:&lt;/i&gt; the JBoss EAP documentation about the CMR resource configuration can be found at section &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_jboss_enterprise_application_platform/7.1/html/development_guide/java_transaction_api_jta#about_the_lrco_optimization_for_single_phase_commit_1pc"&gt; About the LRCO Optimization for Single-phase Commit (1PC)&lt;/a&gt;&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt; The article explained what is the Narayana Commit Markable resource (CMR), it compared it with LRCO and presented its advantages. In the latter part of the article you found how to configure the CMR resource in your application deployed at the &lt;a href="http://wildfly.org/"&gt;WildFly application server&lt;/a&gt;. &lt;br/&gt; If you like to run an application using the commit markable resource feature, check our Narayana quickstart at &lt;a href="https://github.com/jbosstm/quickstart/tree/master/wildfly/commit-markable-resource"&gt; &lt;b&gt;https://github.com/jbosstm/quickstart/tree/master/wildfly/commit-markable-resource&lt;/b&gt;&lt;/a&gt;. &lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/qq44hyr6kbA" height="1" width="1" alt=""/&gt;</content><summary>CMR is neat Narayana feature enabling full XA transaction capability for one non-XA JDBC resource. This gives you a way to engage a database resource to XA transaction even the JDBC driver is not fully XA capable (or you just have a design restriction on it) while transaction data consistency is kept. Last resource commit optimization (aka. LRCO) Maybe you will say "adding one non-XA resource to a...</summary><dc:creator>Ondřej Chaloupka</dc:creator><dc:date>2018-06-28T05:17:00Z</dc:date><feedburner:origLink>http://jbossts.blogspot.com/2018/06/narayana-commit-markable-resource.html</feedburner:origLink></entry><entry><title>Building Syndesis platform with Apache Camel snapshot</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/_kktvrw9pE8/" /><category term="feed_group_name_fusesource" scheme="searchisko:content:tags" /><category term="feed_name_oscerd" scheme="searchisko:content:tags" /><author><name>Andrea Cosentino</name></author><id>searchisko:content:id:jbossorg_blog-building_syndesis_platform_with_apache_camel_snapshot</id><updated>2018-06-28T00:00:00Z</updated><published>2018-06-28T00:00:00Z</published><content type="html">&lt;p&gt;In the last months I worked on &lt;a href="https://syndesis.io/"&gt;Syndesis&lt;/a&gt; project. Syndesis is an hybrid integration platform based on Apache Camel. During this time I had the need to build this platform against a Camel Snapshot version to test some new features I added into the Apache Camel project and it wasn’t truly easy. Adding the possibility to build the platform against different Camel snapshots and versions can be very useful to test Camel master and also to have an idea of how new/updated Camel components behave in this platform. I think it would be useful for end users too.&lt;/p&gt; &lt;h3 id="normal-workflow"&gt;Normal Workflow&lt;/h3&gt; &lt;p&gt;Building Syndesis platform is not super easy at first sight, but it’s very well documented and complete.&lt;/p&gt; &lt;div class="language-bash highlighter-rouge"&gt;&lt;div class="highlight"&gt;&lt;pre class="highlight"&gt;&lt;code&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; syndesis/tools/bin&lt;span class="nv"&gt;$ &lt;/span&gt;./syndesis build &lt;span class="nt"&gt;--help&lt;/span&gt; Run Syndesis builds Usage: syndesis build &lt;span class="o"&gt;[&lt;/span&gt;... options ...] Options &lt;span class="k"&gt;for &lt;/span&gt;build: &lt;span class="nt"&gt;-b&lt;/span&gt; &lt;span class="nt"&gt;--backend&lt;/span&gt; Build only backend modules &lt;span class="o"&gt;(&lt;/span&gt;core, extension, integration, connectors, server, meta&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="nt"&gt;--images&lt;/span&gt; Build only modules with Docker images &lt;span class="o"&gt;(&lt;/span&gt;ui, server, meta, s2i&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="nt"&gt;-m&lt;/span&gt; &lt;span class="nt"&gt;--module&lt;/span&gt; &amp;lt;m1&amp;gt;,&amp;lt;m2&amp;gt;, .. Build modules Modules: ui, server, connector, s2i, meta, integration, extension, common &lt;span class="nt"&gt;-d&lt;/span&gt; &lt;span class="nt"&gt;--dependencies&lt;/span&gt; Build also all project the specified module depends on &lt;span class="nt"&gt;--skip-tests&lt;/span&gt; Skip unit and system &lt;span class="nb"&gt;test &lt;/span&gt;execution &lt;span class="nt"&gt;--skip-checks&lt;/span&gt; Disable all checks &lt;span class="nt"&gt;-f&lt;/span&gt; &lt;span class="nt"&gt;--flash&lt;/span&gt; Skip checks and tests execution &lt;span class="o"&gt;(&lt;/span&gt;fastest mode&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="nt"&gt;-i&lt;/span&gt; &lt;span class="nt"&gt;--image-mode&lt;/span&gt; &amp;lt;mode&amp;gt; &amp;lt;mode&amp;gt; can be - &lt;span class="s2"&gt;"none"&lt;/span&gt; : No images are build &lt;span class="o"&gt;(&lt;/span&gt;default&lt;span class="o"&gt;)&lt;/span&gt; - &lt;span class="s2"&gt;"openshift"&lt;/span&gt; : Build &lt;span class="k"&gt;for &lt;/span&gt;OpenShift image streams - &lt;span class="s2"&gt;"docker"&lt;/span&gt; : Build against a plain Docker daemon - &lt;span class="s2"&gt;"auto"&lt;/span&gt; : Automatically detect whether to use &lt;span class="s2"&gt;"openshift"&lt;/span&gt; or &lt;span class="s2"&gt;"docker"&lt;/span&gt; &lt;span class="nt"&gt;--docker&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="nt"&gt;--image-mode&lt;/span&gt; docker &lt;span class="nt"&gt;--openshift&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="nt"&gt;--image-mode&lt;/span&gt; openshift &lt;span class="nt"&gt;-p&lt;/span&gt; &lt;span class="nt"&gt;--project&lt;/span&gt; &amp;lt;project&amp;gt; Specifies the project to create images &lt;span class="k"&gt;in &lt;/span&gt;when using &lt;span class="s1"&gt;'--openshift'&lt;/span&gt; &lt;span class="nt"&gt;-k&lt;/span&gt; &lt;span class="nt"&gt;--kill-pods&lt;/span&gt; Kill pods after the image has been created. Useful when building with image-mode docker &lt;span class="nt"&gt;-c&lt;/span&gt; &lt;span class="nt"&gt;--clean&lt;/span&gt; Run clean builds &lt;span class="o"&gt;(&lt;/span&gt;mvn clean&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="nt"&gt;--batch-mode&lt;/span&gt; Run mvn &lt;span class="k"&gt;in &lt;/span&gt;batch mode &lt;span class="nt"&gt;--camel-snapshot&lt;/span&gt; Run a build with a specific Camel snapshot. You&lt;span class="s1"&gt;'ll need to set an environment variable CAMEL_SNAPSHOT_VERSION with the SNAPSHOT version you want to use. --man Open HTML documentation in the Syndesis Developer Handbook &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt; &lt;p&gt;I use &lt;a href="https://github.com/minishift/minishift"&gt;Minishift&lt;/a&gt; to play with Syndesis and my normal workflow is the following: First I spin up a Minishift instance&lt;/p&gt; &lt;div class="language-bash highlighter-rouge"&gt;&lt;div class="highlight"&gt;&lt;pre class="highlight"&gt;&lt;code&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; minishift start &lt;span class="nt"&gt;--memory&lt;/span&gt; 8384 &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt; &lt;p&gt;You could need to specify a vm-driver too with the –vm-driver flag.&lt;/p&gt; &lt;p&gt;Then I set the docker environment coming from Minishift&lt;/p&gt; &lt;div class="language-bash highlighter-rouge"&gt;&lt;div class="highlight"&gt;&lt;pre class="highlight"&gt;&lt;code&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="nb"&gt;eval&lt;/span&gt; &lt;span class="k"&gt;$(&lt;/span&gt;minishift docker-env&lt;span class="k"&gt;)&lt;/span&gt; &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt; &lt;p&gt;At this point I’m able to build&lt;/p&gt; &lt;div class="language-bash highlighter-rouge"&gt;&lt;div class="highlight"&gt;&lt;pre class="highlight"&gt;&lt;code&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; syndesis/tools/bin&lt;span class="nv"&gt;$ &lt;/span&gt;./syndesis build &lt;span class="nt"&gt;--openshift&lt;/span&gt; &lt;span class="nt"&gt;--clean&lt;/span&gt; &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt; &lt;p&gt;Once the build it’s done (it may take a while) we are able to deploy Syndesis platform on Minishift&lt;/p&gt; &lt;div class="language-bash highlighter-rouge"&gt;&lt;div class="highlight"&gt;&lt;pre class="highlight"&gt;&lt;code&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; syndesis/tools/bin&lt;span class="nv"&gt;$ &lt;/span&gt;./syndesis minishift &lt;span class="nt"&gt;--install&lt;/span&gt; &lt;span class="nt"&gt;--openshift&lt;/span&gt; &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt; &lt;p&gt;Once the deployment is finished we are able to start using Syndesis platform.&lt;/p&gt; &lt;h3 id="building-with-a-camel-snapshot"&gt;Building with a Camel Snapshot&lt;/h3&gt; &lt;p&gt;The option you’ll need in this case will be –camel-snapshot, in combination with an environment variable called &lt;code class="highlighter-rouge"&gt;CAMEL_SNAPSHOT_VERSION&lt;/code&gt;. In my case I need to test a new feature in a component from Camel 2.21.2-SNAPSHOT. The workflow to obtain a running Syndesis instance based on Camel 2.21.2-SNAPSHOT is the following (supposing you have a running Minishift).&lt;/p&gt; &lt;p&gt;Set the docker environment coming from Minishift&lt;/p&gt; &lt;div class="language-bash highlighter-rouge"&gt;&lt;div class="highlight"&gt;&lt;pre class="highlight"&gt;&lt;code&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="nb"&gt;eval&lt;/span&gt; &lt;span class="k"&gt;$(&lt;/span&gt;minishift docker-env&lt;span class="k"&gt;)&lt;/span&gt; &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt; &lt;p&gt;Export &lt;code class="highlighter-rouge"&gt;CAMEL_SNAPSHOT_VERSION&lt;/code&gt; environment variable&lt;/p&gt; &lt;div class="language-bash highlighter-rouge"&gt;&lt;div class="highlight"&gt;&lt;pre class="highlight"&gt;&lt;code&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="nb"&gt;export &lt;/span&gt;&lt;span class="nv"&gt;CAMEL_SNAPSHOT_VERSION&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"2.21.2-SNAPSHOT"&lt;/span&gt; &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt; &lt;p&gt;Run a Syndesis build with –camel-snapshot flag enabled&lt;/p&gt; &lt;div class="language-bash highlighter-rouge"&gt;&lt;div class="highlight"&gt;&lt;pre class="highlight"&gt;&lt;code&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; syndesis/tools/bin&lt;span class="nv"&gt;$ &lt;/span&gt;./syndesis build &lt;span class="nt"&gt;--openshift&lt;/span&gt; &lt;span class="nt"&gt;--clean&lt;/span&gt; &lt;span class="nt"&gt;--camel-snapshot&lt;/span&gt; &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt; &lt;p&gt;Once the build finished, you can deploy your Syndesis on Minishift&lt;/p&gt; &lt;div class="language-bash highlighter-rouge"&gt;&lt;div class="highlight"&gt;&lt;pre class="highlight"&gt;&lt;code&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; syndesis/tools/bin&lt;span class="nv"&gt;$ &lt;/span&gt;./syndesis minishift &lt;span class="nt"&gt;--install&lt;/span&gt; &lt;span class="nt"&gt;--openshift&lt;/span&gt; &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt; &lt;p&gt;This is all you need to test a Syndesis platform based on Camel snapshot.&lt;/p&gt; &lt;h3 id="conclusion"&gt;Conclusion&lt;/h3&gt; &lt;p&gt;In the future I’ll blog about the Syndesis platform a bit more. If you want to contribute you can start from the &lt;a href="https://github.com/syndesisio/syndesis/"&gt;Github project&lt;/a&gt;, the &lt;a href="https://syndesis.io/"&gt;site&lt;/a&gt; or an &lt;a href="https://github.com/syndesisio/syndesis-extensions"&gt;extension&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/_kktvrw9pE8" height="1" width="1" alt=""/&gt;</content><summary>In the last months I worked on Syndesis project. Syndesis is an hybrid integration platform based on Apache Camel. During this time I had the need to build this platform against a Camel Snapshot version to test some new features I added into the Apache Camel project and it wasn’t truly easy. Adding the possibility to build the platform against different Camel snapshots and versions can be very use...</summary><dc:creator>Andrea Cosentino</dc:creator><dc:date>2018-06-28T00:00:00Z</dc:date><feedburner:origLink>http://oscerd.github.io/2018/06/28/building-syndesis-with-camel-snapshot/</feedburner:origLink></entry><entry><title>DesOps is “DevOps 2.0”</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/JU5Mi4El6_w/" /><category term="agile" scheme="searchisko:content:tags" /><category term="design" scheme="searchisko:content:tags" /><category term="DesignOps" scheme="searchisko:content:tags" /><category term="DesOPs" scheme="searchisko:content:tags" /><category term="devops" scheme="searchisko:content:tags" /><category term="domain-driven design" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="SDLC" scheme="searchisko:content:tags" /><category term="UI/UX" scheme="searchisko:content:tags" /><author><name>Samir Dash</name></author><id>searchisko:content:id:jbossorg_blog-desops_is_devops_2_0</id><updated>2018-06-27T21:32:36Z</updated><published>2018-06-27T21:32:36Z</published><content type="html">&lt;p&gt;As we discussed in the &lt;a href="https://developers.redhat.com/blog/2018/06/22/desops-the-next-wave-in-design/"&gt;last post&lt;/a&gt;, most of &lt;em&gt;DevOps&lt;/em&gt; today focuses on the process blocks that mostly impact engineering or technical aspects of a product rather than the design aspect. Even though &lt;em&gt; DesOps&lt;/em&gt; was primarily born out of the primary need of how to design at scale, the factors that shaped it are of a similar nature to the factors that shaped &lt;em&gt;DevOps&lt;/em&gt;.&lt;/p&gt; &lt;p&gt;With recent software delivery processes, for example, the Agile process and Continuous Integration (CI) and Continuous Deployment (CD)of code, the &lt;em&gt;DevOps&lt;/em&gt; approach provided a faster highway to ensure faster delivery with low risks. So the earlier SDLC model got redefined over time with Agile and then with &lt;em&gt;DevOps&lt;/em&gt; to its current shape.&lt;/p&gt; &lt;p&gt;However, because design is an integral part of any product delivered, there is a need to ensure that gaps are bridged between the traditional design lifecycle and the fast track of the &lt;em&gt;DevOps&lt;/em&gt; development lifecycle. &lt;em&gt;DesOps&lt;/em&gt; and &lt;em&gt;DevOps&lt;/em&gt; both are complementary to each other. The design delivery process improvements try to optimize the overall delivery process and thereby contribute to &lt;em&gt;DevOps&lt;/em&gt;, for example, in aspects such as testing of the product that involves design aspects, usability, accessibility, etc.&lt;/p&gt; &lt;p&gt;The need for tighter integration between the design team and the engineering team became a necessity to ensure to design at scale. During the past two to three years, the top five big companies have made heavy investments in this area that have paved the way for other organizations and design communities to be more explorative in this area.&lt;/p&gt; &lt;p&gt;&lt;span id="more-503557"&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;img class="wp-image-503577 size-full aligncenter" src="https://developers.redhat.com/blog/wp-content/uploads/2018/06/desopsdevops2.0.png" alt="DesOps = DevOps 2.0" width="1492" height="708" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/06/desopsdevops2.0.png 1492w, https://developers.redhat.com/blog/wp-content/uploads/2018/06/desopsdevops2.0-300x142.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/06/desopsdevops2.0-768x364.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2018/06/desopsdevops2.0-1024x486.png 1024w" sizes="(max-width: 1492px) 100vw, 1492px" /&gt;&lt;/p&gt; &lt;p&gt;The implications of &lt;em&gt;DesOps&lt;/em&gt; are reflected in the outcome, where the silos among the teams and disciplines get reduced. Along with this, &lt;em&gt;DesOps&lt;/em&gt; improves the collaboration among cross-functional teams and work practices, which contributes to minimizing waste in the delivery process.&lt;/p&gt; &lt;p&gt;Every product lifecycle has one core goal towards which it strives: reaching customer delight by delivering the value. The design process associated with &lt;em&gt;DesOps&lt;/em&gt; helps in understanding, capturing, and delivering that value.&lt;/p&gt; &lt;p&gt;But conventional business processes were more keen on getting the outputs of each process block, which can be fed into the next block, thereby reaching a stage that ultimately delivered the value. Many such practices failed in achieving customer delight because the processes used were not based on the customer shift from outputs to outcomes.&lt;/p&gt; &lt;p&gt;If we see the &lt;em&gt;DesOps&lt;/em&gt; processes in terms of a value system, we will see at a high level that &lt;em&gt;DesOps&lt;/em&gt; touches upon three major areas:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Understanding value&lt;/li&gt; &lt;li&gt;Creating value&lt;/li&gt; &lt;li&gt;Capturing and delivering value&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;As discussed in the last post, in the value system approach,&lt;em&gt; understanding value&lt;/em&gt; is about reaching a vision. &lt;em&gt;Creating value&lt;/em&gt; is broadly about reaching a roadmap with &lt;em&gt;Minimum Viable Product&lt;/em&gt; (MVP). &lt;em&gt;Capturing and delivery value &lt;/em&gt;is about running the backlog and sprints and ensuring delivery until the end users have access.&lt;/p&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;p&gt;&lt;img class="alignnone size-full wp-image-503607" src="https://developers.redhat.com/blog/wp-content/uploads/2018/06/desopsdevops2-overlap.png" alt="" width="1423" height="704" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/06/desopsdevops2-overlap.png 1423w, https://developers.redhat.com/blog/wp-content/uploads/2018/06/desopsdevops2-overlap-300x148.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/06/desopsdevops2-overlap-768x380.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2018/06/desopsdevops2-overlap-1024x507.png 1024w" sizes="(max-width: 1423px) 100vw, 1423px" /&gt;&lt;/p&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;p&gt;Because design is associated with entities and attributes beyond the quantifiable science of connecting with disciplines that are associated with the emotional aspects of the qualitative approach, the implementation of &lt;em&gt;DesOps&lt;/em&gt; is more fluid than the case of &lt;em&gt;DevOps&lt;/em&gt;.&lt;/p&gt; &lt;p&gt;For instance, if we plot the techniques and practices of any domain according to the left brain–right brain analogy, we can see that most of the practices having soft-attributes or dealing with human emotions, purpose, and behavior will fall into the creative aspect, which involves some kind of design approach to problem-solving.&lt;/p&gt; &lt;p&gt;As one example, you can see in the following figure that the right side shows the mapping of practices involved with software incident reporting. Here you can easily notice the pattern.&lt;/p&gt; &lt;p&gt;&lt;img class="size-full wp-image-503797 aligncenter" src="https://developers.redhat.com/blog/wp-content/uploads/2018/06/leftright.png" alt="" width="1224" height="803" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/06/leftright.png 1224w, https://developers.redhat.com/blog/wp-content/uploads/2018/06/leftright-300x197.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/06/leftright-768x504.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2018/06/leftright-1024x672.png 1024w" sizes="(max-width: 1224px) 100vw, 1224px" /&gt;&lt;/p&gt; &lt;p class="selectionShareable"&gt;The typical belief is that the left side of the brain mostly processes logical thinking, while the right side is more about emotional thinking. Based on this popular analogy, when we map across a straight line from left to right (refer to the previous diagram) the different aspects involved in different stages of SDLC for a digital product, we will notice the logical and more human-centered aspects are divided by an imaginary line from the center. We will also notice the gradual progression of the emotional index for the components from left to right. This helps to demonstrate how the more-human angle is involved as we move from the areas that DevOps touches upon to the areas that &lt;em&gt;DesOps&lt;/em&gt; touches, because &lt;em&gt;DesOps&lt;/em&gt; touches upon the design and business aspects of the value chain.&lt;/p&gt; &lt;p&gt;From foundational guidelines, &lt;em&gt;DevOps&lt;/em&gt; inspires the &lt;em&gt;DesOps&lt;/em&gt; mindset at a high level:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Partnering with customers for improving business value&lt;/li&gt; &lt;li&gt;Working together towards a shared vision&lt;/li&gt; &lt;li&gt;Delivering incremental value&lt;/li&gt; &lt;li&gt;Investing in quality&lt;/li&gt; &lt;li&gt; Empowering team members&lt;/li&gt; &lt;li&gt;Setting up clear accountability in teams&lt;/li&gt; &lt;li&gt;Learning from experiences&lt;/li&gt; &lt;li&gt; Advocating open communications and transparency&lt;/li&gt; &lt;li&gt;Being agile and adapting to change&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;In such a context, if we look into &lt;em&gt;DesOps&lt;/em&gt;, it makes a lot of sense in the following key principles:&lt;/p&gt; &lt;p&gt;&lt;img class="size-full wp-image-503807 aligncenter" src="https://developers.redhat.com/blog/wp-content/uploads/2018/06/desops222.png" alt="" width="1920" height="1329" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/06/desops222.png 1920w, https://developers.redhat.com/blog/wp-content/uploads/2018/06/desops222-300x208.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/06/desops222-768x532.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2018/06/desops222-1024x709.png 1024w" sizes="(max-width: 1920px) 100vw, 1920px" /&gt;&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Implement &lt;em&gt;DesOps&lt;/em&gt; to follow service design methodologies.&lt;/li&gt; &lt;li&gt;The feedback loop should cut across the product lifecycle.&lt;/li&gt; &lt;li&gt;Empower stakeholders for better decision-making—hypothesis and data-driven decision-making for design and development.&lt;/li&gt; &lt;li&gt;Empower design thinking.&lt;/li&gt; &lt;li&gt;Advocate lean methodologies and Agile philosophies.&lt;/li&gt; &lt;li&gt;Translate user-centered design into an actual process that can be used on the ground.&lt;/li&gt; &lt;li&gt;Advocate cohesive designers, stakeholders, and developers into team play.&lt;/li&gt; &lt;li&gt;Technology decisions should be guided by lowering the boundaries between roles and automation to reduce waste and reduce repetitive jobs to work for the product and the project.&lt;/li&gt; &lt;li&gt;Redesign and re-engineer the processes.&lt;/li&gt; &lt;li&gt;Enable reviews based on data-driven benchmarks.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;So how does this all fit in? At a crude level, the &lt;em&gt;DesOps&lt;/em&gt; processes may have something like the following structure when they are translated in terms of technology and ecosystems, in a similar fashion as DevOps.&lt;/p&gt; &lt;p&gt;&lt;img class="aligncenter size-full wp-image-503827" src="https://developers.redhat.com/blog/wp-content/uploads/2018/06/flow2.png" alt="" width="1500" height="323" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/06/flow2.png 1500w, https://developers.redhat.com/blog/wp-content/uploads/2018/06/flow2-300x65.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/06/flow2-768x165.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2018/06/flow2-1024x221.png 1024w" sizes="(max-width: 1500px) 100vw, 1500px" /&gt;&lt;/p&gt; &lt;ol&gt; &lt;li&gt;First, we should create the design benchmarks (that includes qualitative as well as quantitative metrics) from the information at the design stage that can be used in comparing the product features against metrics based on this design benchmark.&lt;/li&gt; &lt;li&gt;Then, automate and perform manual tracking of the product during runtime (in real time and in the true context), and then categorize and collate this data.&lt;/li&gt; &lt;li&gt;This involves creating features to support the user feedback cycle and user testing aspects (exploratory, split testing capabilities).&lt;/li&gt; &lt;li&gt;Collect all standards and specifications on different aspects of heuristics to ensure that at least at the basic level the standard principles are followed.&lt;/li&gt; &lt;li&gt;On the ground, in the context of the eco-system and technologies, build the critical components that would collect and process all the data collected in all these stages and generate the desired metrics and inferences and also contribute in bringing continuous integration and continuous delivery blocks to run the process.&lt;/li&gt; &lt;li&gt;Build the unit to generate the model to map the data and compare it against the metrics.&lt;/li&gt; &lt;li&gt;Build the cognitive unit that can compare the data and apply the correct models and metrics to carry out the filtering of the data and generate the insights which can be shared as actionable output to the end-user/customer.&lt;/li&gt; &lt;li&gt;And ensure in all these stages that the feedback loop is connected spatially and acting as a meaningful neural network that helps in informed decision-making.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Keep tuned in to stay with me on this journey into &lt;em&gt;DesOps&lt;/em&gt;!&lt;/p&gt; &lt;p&gt;&lt;strong&gt;(Note: Based on my book &lt;em&gt;The DesOps Enterprise: Overview &amp;#38; Culture&lt;/em&gt;)&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F06%2F27%2Fdesops-is-devops-2-0%2F&amp;#38;linkname=DesOps%20is%20%E2%80%9CDevOps%202.0%E2%80%9D" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F06%2F27%2Fdesops-is-devops-2-0%2F&amp;#38;linkname=DesOps%20is%20%E2%80%9CDevOps%202.0%E2%80%9D" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F06%2F27%2Fdesops-is-devops-2-0%2F&amp;#38;linkname=DesOps%20is%20%E2%80%9CDevOps%202.0%E2%80%9D" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F06%2F27%2Fdesops-is-devops-2-0%2F&amp;#38;linkname=DesOps%20is%20%E2%80%9CDevOps%202.0%E2%80%9D" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F06%2F27%2Fdesops-is-devops-2-0%2F&amp;#38;linkname=DesOps%20is%20%E2%80%9CDevOps%202.0%E2%80%9D" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F06%2F27%2Fdesops-is-devops-2-0%2F&amp;#38;linkname=DesOps%20is%20%E2%80%9CDevOps%202.0%E2%80%9D" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F06%2F27%2Fdesops-is-devops-2-0%2F&amp;#38;linkname=DesOps%20is%20%E2%80%9CDevOps%202.0%E2%80%9D" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F06%2F27%2Fdesops-is-devops-2-0%2F&amp;#38;linkname=DesOps%20is%20%E2%80%9CDevOps%202.0%E2%80%9D" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F06%2F27%2Fdesops-is-devops-2-0%2F&amp;#38;title=DesOps%20is%20%E2%80%9CDevOps%202.0%E2%80%9D" data-a2a-url="https://developers.redhat.com/blog/2018/06/27/desops-is-devops-2-0/" data-a2a-title="DesOps is “DevOps 2.0”"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/06/27/desops-is-devops-2-0/"&gt;DesOps is &amp;#8220;DevOps 2.0&amp;#8221;&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/JU5Mi4El6_w" height="1" width="1" alt=""/&gt;</content><summary>As we discussed in the last post, most of DevOps today focuses on the process blocks that mostly impact engineering or technical aspects of a product rather than the design aspect. Even though  DesOps was primarily born out of the primary need of how to design at scale, the factors that shaped it are of a similar nature to the factors that shaped DevOps. With recent software delivery processes, fo...</summary><dc:creator>Samir Dash</dc:creator><dc:date>2018-06-27T21:32:36Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2018/06/27/desops-is-devops-2-0/</feedburner:origLink></entry><entry><title>Keycloak on Kubernetes</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/-EIEUoVLx2s/keycloak-on-kubernetes.html" /><category term="feed_group_name_keycloak" scheme="searchisko:content:tags" /><category term="feed_name_keycloak" scheme="searchisko:content:tags" /><author><name>Stian Thorgersen</name></author><id>searchisko:content:id:jbossorg_blog-keycloak_on_kubernetes</id><updated>2018-06-27T20:15:37Z</updated><published>2018-06-27T20:15:00Z</published><content type="html">&lt;p&gt;If you'd like to get started with using Keycloak on Kubernetes check out &lt;a href="https://youtu.be/A_BYZ7hHWXE"&gt;this screencast&lt;/a&gt;. If you'd rather try it out yourself check out &lt;a href="https://github.com/stianst/demo-kubernetes"&gt;this GitHub repository&lt;/a&gt; that contains the instructions as well as all the bits you'll need to reproduce what is shown in the screencast.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/-EIEUoVLx2s" height="1" width="1" alt=""/&gt;</content><summary>If you'd like to get started with using Keycloak on Kubernetes check out this screencast. If you'd rather try it out yourself check out this GitHub repository that contains the instructions as well as all the bits you'll need to reproduce what is shown in the screencast.</summary><dc:creator>Stian Thorgersen</dc:creator><dc:date>2018-06-27T20:15:00Z</dc:date><feedburner:origLink>http://blog.keycloak.org/2018/06/keycloak-on-kubernetes.html</feedburner:origLink></entry></feed>
